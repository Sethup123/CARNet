{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0efeb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "from typing import Tuple\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import numpy as np; np.random.seed(1)\n",
    "import torch; torch.manual_seed(1)\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from scipy import io\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.set_printoptions(precision=5,sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd3830",
   "metadata": {},
   "source": [
    "# Golbal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736b0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'SUN' \n",
    "DATA_DIR = f'../../Datasets/{DATASET}'\n",
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a591479b",
   "metadata": {},
   "source": [
    "# Attribute Refinement Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0528e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exist(x):\n",
    "    return x is not None\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self,fn):\n",
    "        super().__init__()\n",
    "        self.fn=fn\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.fn(x)+x\n",
    "\n",
    "class GatingUnit(nn.Module):\n",
    "    def __init__(self,dim,len_sen):\n",
    "        super().__init__()\n",
    "        self.ln=nn.LayerNorm(dim)\n",
    "        self.proj=nn.Conv1d(len_sen,len_sen,1)\n",
    "\n",
    "        nn.init.zeros_(self.proj.weight)\n",
    "        nn.init.ones_(self.proj.bias)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        res,gate=torch.chunk(x,2,-1)\n",
    "        gate=self.ln(gate) \n",
    "        gate=self.proj(gate.unsqueeze(-1)) \n",
    "        gate = gate.squeeze(-1)\n",
    "        return res*gate\n",
    "\n",
    "class ARN(nn.Module):\n",
    "    def __init__(self,num_tokens=None,len_sen=49,dim=512,d_ff=1024,num_layers=6):\n",
    "        super().__init__()\n",
    "        self.num_layers=num_layers\n",
    "        self.embedding=nn.Embedding(num_tokens,dim) if exist(num_tokens) else nn.Identity()\n",
    "\n",
    "        self.arn=nn.ModuleList([Residual(nn.Sequential(OrderedDict([\n",
    "            ('ln1_%d'%i,nn.LayerNorm(dim)),\n",
    "            ('fc1_%d'%i,nn.Linear(dim,d_ff*2)),\n",
    "            ('gelu_%d'%i,nn.GELU()),\n",
    "            ('sgu_%d'%i,GatingUnit(d_ff,len_sen)),\n",
    "            ('fc2_%d'%i,nn.Linear(d_ff,dim)),\n",
    "        ])))  for i in range(num_layers)])\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        #embedding\n",
    "        embeded=self.embedding(x)\n",
    "\n",
    "        #ARN\n",
    "        y=nn.Sequential(*self.arn)(embeded)\n",
    "                \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1736e76",
   "metadata": {},
   "source": [
    "# Circle Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a098174",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleLoss(nn.Module):\n",
    "    def __init__(self, m: float, gamma: float) -> None:\n",
    "        super(CircleLoss, self).__init__()\n",
    "        self.m = m\n",
    "        self.gamma = gamma\n",
    "        self.soft_plus = nn.Softplus()\n",
    "\n",
    "    def forward(self, sp: Tensor, sn: Tensor, logits=None, N=None, C=None) -> Tensor:\n",
    "        sp_logit = logits[sp].view(N,1)\n",
    "        sn_logit = logits[sn].view(N,C-1)\n",
    "\n",
    "        margin = self.m\n",
    "\n",
    "        ap = torch.clamp_min(- sp_logit.detach() + 1 + margin, min=0.)\n",
    "        an = torch.clamp_min(sn_logit.detach() + margin, min=0.)\n",
    "\n",
    "        delta_p = 1 - margin\n",
    "        delta_n = margin\n",
    "\n",
    "        logit_p = - ap * (sp_logit - delta_p) * self.gamma\n",
    "        logit_n = an * (sn_logit - delta_n) * self.gamma\n",
    "\n",
    "        loss = self.soft_plus(torch.logsumexp(logit_n, dim=1) + torch.logsumexp(logit_p, dim=1))\n",
    "        return loss\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2554d1ac",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "018767a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(task,task_seen_class,task_unseen_class,reg):\n",
    "    eps=0.01\n",
    "    net.eval()\n",
    "    \n",
    "    seen_dict = {}\n",
    "    seen_dict_no = {}\n",
    "    seen_acc_list = []    \n",
    "    \n",
    "    for jj in range(len(task_seen_class)):\n",
    "        mapped_class = task_seen_class[jj]\n",
    "        seen_dict[mapped_class] = 0\n",
    "        seen_dict_no[mapped_class] = 0\n",
    "        \n",
    "        \n",
    "    \n",
    "    unseen_dict = {}\n",
    "    unseen_dict_no = {}\n",
    "    unseen_acc_list = []    \n",
    "        \n",
    "    for jj in range(len(task_unseen_class)):\n",
    "        mapped_class = task_unseen_class[jj]\n",
    "        unseen_dict[mapped_class] = 0\n",
    "        unseen_dict_no[mapped_class] = 0\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct=0\n",
    "        Nsamples=0\n",
    "        for i, (feats,targets) in enumerate(testseen_dataloader):\n",
    "            feats = feats.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            logits = net(feats, attributes)\n",
    "            logits[:, task_seen_class] *= reg\n",
    "            pred = logits.max(1, keepdim=True)[1]\n",
    "            \n",
    "            for jj in range(targets.shape[0]):\n",
    "                if pred[jj] == targets[jj]:\n",
    "                   seen_dict[targets[jj].cpu().numpy().item()] += 1\n",
    "                \n",
    "                seen_dict_no[targets[jj].cpu().numpy().item()] += 1\n",
    "            \n",
    "            correct += pred.eq(targets.view_as(pred)).sum().item()\n",
    "            Nsamples+=targets.shape[0]\n",
    "            \n",
    "        for jj in range(len(task_seen_class)):\n",
    "            mapped_class = task_seen_class[jj]\n",
    "            seen_acc_list.append(seen_dict[mapped_class]/(seen_dict_no[mapped_class] * 1.0 + 1e-5))\n",
    "        \n",
    "        seen_acc = np.mean(np.array(seen_acc_list))\n",
    "        \n",
    "        \n",
    "        correct=0\n",
    "        Nsamples=0\n",
    "        for i, (feats,targets) in enumerate(testunseen_dataloader):\n",
    "            feats = feats.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            logits = net(feats, attributes)\n",
    "            logits[:, task_seen_class] *= reg\n",
    "            pred = logits.max(1, keepdim=True)[1]\n",
    "            for jj in range(targets.shape[0]):\n",
    "                if pred[jj] == targets[jj]:\n",
    "                   unseen_dict[targets[jj].cpu().numpy().item()] += 1\n",
    "\n",
    "                unseen_dict_no[targets[jj].cpu().numpy().item()] += 1           \n",
    "\n",
    "        for jj in range(len(task_unseen_class)):\n",
    "            mapped_class = task_unseen_class[jj]\n",
    "            unseen_acc_list.append(unseen_dict[mapped_class]/(unseen_dict_no[mapped_class] * 1.0 + 1e-5))\n",
    "\n",
    "        unseen_acc = np.mean(np.array(unseen_acc_list))        \n",
    "                    \n",
    "        h_mean_class_wise = (2*seen_acc*unseen_acc)/(seen_acc+unseen_acc)  \n",
    "        return seen_acc, unseen_acc,h_mean_class_wise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3173306",
   "metadata": {},
   "source": [
    "# Initialize the Attribute Refinement Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b771eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "\n",
    "arn = ARN(len_sen=1024,dim=102,d_ff=1024, num_layers=1)\n",
    "arn = arn.to(DEVICE)\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a489a0",
   "metadata": {},
   "source": [
    "# Class Balanced Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b302ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ER_MEM():\n",
    "    def __init__(self, samples_per_class=5, total_classes=717, memory_batch_size=int(512 + 256)):\n",
    "        self.trainData_memory = []\n",
    "        self.trainLabels_memory = []\n",
    "        self.mem_size = samples_per_class * total_classes\n",
    "        self.mem_batch_size = memory_batch_size\n",
    "        self.mem_sum = 0\n",
    "        self.mem_counter = [0]*total_classes\n",
    "        self.largest_class_list = [0]*total_classes\n",
    "        self.samples_seen = [0]*total_classes\n",
    "        \n",
    "    def reservoir_mem_select_data(self, trainData, trainLabels):\n",
    "        \n",
    "        # when the memory is empty return the train data as it is\n",
    "        if len(self.trainData_memory) == 0:\n",
    "            return trainData, trainLabels\n",
    "\n",
    "        # when the memory size is less than mem_batch size use all the data in memory\n",
    "        elif len(self.trainData_memory) < self.mem_batch_size:\n",
    "            trainData_memory_batch = torch.tensor(np.array(self.trainData_memory), dtype=torch.float32)\n",
    "            trainLabels_memory_batch = torch.tensor(np.array(self.trainLabels_memory), dtype=torch.long)\n",
    "\n",
    "            trainData = torch.cat((trainData, trainData_memory_batch), dim=0)\n",
    "            trainLabels = torch.cat((trainLabels, trainLabels_memory_batch), dim=0)\n",
    "                        \n",
    "            return trainData, trainLabels\n",
    "\n",
    "        # when the memory size is greater than mem_batch size randomly select data of size mem_batch\n",
    "        elif len(self.trainData_memory) >= self.mem_batch_size:\n",
    "            mem_index = np.random.choice(len(self.trainData_memory), self.mem_batch_size, replace=False)\n",
    "            \n",
    "            trainData_memory_batch = torch.tensor(np.array(self.trainData_memory)[mem_index], dtype=torch.float32)\n",
    "            trainLabels_memory_batch = torch.tensor(np.array(self.trainLabels_memory)[mem_index], dtype=torch.long)\n",
    "\n",
    "            trainData = torch.cat((trainData, trainData_memory_batch), dim=0)\n",
    "            trainLabels = torch.cat((trainLabels, trainLabels_memory_batch), dim=0)\n",
    "\n",
    "            return trainData, trainLabels\n",
    "        \n",
    "    \n",
    "    \n",
    "    def reservoir_mem_update(self, trainData_copy, trainLabels_copy):\n",
    "        for ll in range(len(trainData_copy)):\n",
    "            \n",
    "            # when the memory is not full directly add the data to memory\n",
    "            if len(self.trainData_memory) < self.mem_size:\n",
    "                self.trainData_memory.append(trainData_copy[ll])\n",
    "                self.trainLabels_memory.append(trainLabels_copy[ll])\n",
    "                \n",
    "                self.mem_counter[trainLabels_copy[ll]] = self.mem_counter[trainLabels_copy[ll]] + 1\n",
    "                self.mem_sum = sum(self.mem_counter)\n",
    "                \n",
    "                assert self.mem_sum <= self.mem_size\n",
    "\n",
    "            # When the memory is full update the memory based on reservoir strategy\n",
    "            else:\n",
    "                largest_class = np.argmax(self.mem_counter)\n",
    "                self.largest_class_list[largest_class] = 1\n",
    "                 \n",
    "                current_class_state = self.largest_class_list[trainLabels_copy[ll]]\n",
    "                \n",
    "                assert largest_class < 717\n",
    "                assert current_class_state <= 1\n",
    "                \n",
    "                if current_class_state == 1:\n",
    "                    no_samples = self.mem_counter[trainLabels_copy[ll]]\n",
    "                    no_samples_seen = self.samples_seen[trainLabels_copy[ll]]\n",
    "                    desired_prob = no_samples/no_samples_seen\n",
    "                    assert desired_prob <= 1\n",
    "                    prob = np.random.uniform(0,1,1)\n",
    "                    if prob <= desired_prob:\n",
    "                        idx = [i for i, x in enumerate(self.trainLabels_memory) if x == trainLabels_copy[ll]]\n",
    "                        assert len(idx) == self.mem_counter[trainLabels_copy[ll]]\n",
    "                        idx_selected = np.random.choice(idx, 1)[0]\n",
    "                        self.trainData_memory[idx_selected] = trainData_copy[ll]\n",
    "                        self.trainLabels_memory[idx_selected] = trainLabels_copy[ll]                        \n",
    "                        \n",
    "                        \n",
    "                else:\n",
    "                    idx = [i for i, x in enumerate(self.trainLabels_memory) if x == largest_class]\n",
    "                    assert len(idx) == self.mem_counter[largest_class]\n",
    "                    idx_selected = np.random.choice(idx, 1)[0]    \n",
    "                    self.trainData_memory[idx_selected] = trainData_copy[ll]\n",
    "                    self.trainLabels_memory[idx_selected] = trainLabels_copy[ll]\n",
    "                    \n",
    "                    self.mem_counter[trainLabels_copy[ll]] += 1\n",
    "                    self.mem_counter[largest_class] -= 1\n",
    "                    self.mem_sum = sum(self.mem_counter)\n",
    "                \n",
    "                    assert self.mem_sum == self.mem_size    \n",
    "                \n",
    "                \n",
    "            self.samples_seen[trainLabels_copy[ll]] += 1\n",
    "\n",
    "er_mem = ER_MEM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6c3840",
   "metadata": {},
   "source": [
    "# Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47bbed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<=============== Loading data for SUN ===============>\n"
     ]
    }
   ],
   "source": [
    "print(f'<=============== Loading data for {DATASET} ===============>')\n",
    "data = io.loadmat(f'{DATA_DIR}/res101.mat')\n",
    "attrs_mat = io.loadmat(f'{DATA_DIR}/att_splits.mat')\n",
    "feature = data['features'].T.astype(np.float32)\n",
    "label = data['labels'].squeeze() - 1 # Using \"-1\" here and for idx to normalize to 0-index\n",
    "trainval_loc = attrs_mat['trainval_loc'].squeeze() - 1\n",
    "test_seen_loc = attrs_mat['test_seen_loc'].squeeze() - 1\n",
    "test_unseen_loc = attrs_mat['test_unseen_loc'].squeeze() - 1\n",
    "attribute = attrs_mat['att'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0bcf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features.shape: (10320, 2048)\n",
      "train_label.shape:  (10320, 1)\n",
      "all_attributes.shape:  (717, 102)\n",
      "test_features.shape:  (1440, 2048)\n",
      "test_label.shape:  (1440, 1)\n",
      "testclasses_id.shape:  (72,)\n",
      "test_attributes.shape:  torch.Size([72, 102])\n",
      "test_seen_features.shape:  torch.Size([2580, 2048])\n"
     ]
    }
   ],
   "source": [
    "x = feature[trainval_loc] # train_features\n",
    "train_label = label[trainval_loc].astype(int)  # train_label\n",
    "att = attribute[train_label] # train attributes\n",
    "\n",
    "x_test = feature[test_unseen_loc]  # test_feature\n",
    "test_label = label[test_unseen_loc].astype(int) # test_label\n",
    "x_test_seen = feature[test_seen_loc]  #test_seen_feature\n",
    "test_label_seen = label[test_seen_loc].astype(int) # test_seen_label\n",
    "test_id = np.unique(test_label)   # test_id\n",
    "att_pro = attribute[test_id]      # test_attribute\n",
    "\n",
    "\n",
    "# train set\n",
    "train_features=x\n",
    "print('train_features.shape: ' + str(train_features.shape))\n",
    "\n",
    "train_label=np.array(torch.from_numpy(train_label).unsqueeze(1))\n",
    "print('train_label.shape:  '+str(train_label.shape))\n",
    "\n",
    "# attributes\n",
    "all_attributes=np.array(attribute)\n",
    "print('all_attributes.shape:  '+str(all_attributes.shape))\n",
    "\n",
    "\n",
    "attributes = torch.from_numpy(attribute)\n",
    "attributes = attributes / attributes.norm(dim=1, keepdim=True) * np.sqrt(attributes.shape[1])\n",
    "\n",
    "# test set\n",
    "test_features=x_test\n",
    "print('test_features.shape:  '+ str(test_features.shape))\n",
    "\n",
    "test_label=np.array(torch.from_numpy(test_label).unsqueeze(1))\n",
    "print('test_label.shape:  ' +str(test_label.shape))\n",
    "\n",
    "testclasses_id = np.array(test_id)\n",
    "print('testclasses_id.shape:  ' +str(testclasses_id.shape))\n",
    "\n",
    "test_attributes = torch.from_numpy(att_pro).float()\n",
    "print('test_attributes.shape:  ' +str(test_attributes.shape))\n",
    "\n",
    "\n",
    "test_seen_features = torch.from_numpy(x_test_seen)\n",
    "print('test_seen_features.shape:  ' +str(test_seen_features.shape))\n",
    "\n",
    "test_seen_label = torch.from_numpy(test_label_seen)\n",
    "\n",
    "\n",
    "unq_train_labels=np.unique(train_label)\n",
    "unq_test_labels=np.unique(test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20882ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1=np.concatenate([train_features,test_features],0)\n",
    "Label1=np.concatenate([train_label,test_label],0)\n",
    "\n",
    "Data=np.float32(np.concatenate([Data1,x_test_seen],0))\n",
    "Label=np.concatenate([Label1.squeeze(),test_label_seen],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297b416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% data are kept for the test of seen classes\n",
    "\n",
    "Nseen=Label.shape[0]\n",
    "ind=random.sample(range(Nseen), int(Nseen*0.2))\n",
    "seentest_data=[torch.from_numpy(Data[ind]),torch.from_numpy(Label[ind])]\n",
    "    \n",
    "# 80% are kep for the seen class train data\n",
    "ind=np.setdiff1d(range(Nseen),ind)\n",
    "seentrain_data=[torch.from_numpy(Data[ind]),torch.from_numpy(Label[ind])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "316eecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class all_arguments():\n",
    "    cuda=True\n",
    "    iterations=100\n",
    "    hdim=2048\n",
    "    feat_dim=2048\n",
    "    attri_dim=102\n",
    "    task_split=[47,47,47,48,48,48,48,48,48,48,48,48,48,48,48]\n",
    "    N_class=717\n",
    "    task=15\n",
    "    \n",
    "args=all_arguments()\n",
    "\n",
    "class_per_task=int(args.N_class/args.task)\n",
    "all_class=np.unique(Label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe6eb5",
   "metadata": {},
   "source": [
    "# Function To Get The Data For Each Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a92bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_data(task):\n",
    "    # dataset for the seen and unseen for each task\n",
    "    current_task_class=all_class[int(np.sum(args.task_split[:task-1])):int(np.sum(args.task_split[:task]))]\n",
    "    task_testseen_class=all_class[:int(np.sum(args.task_split[:task]))]\n",
    "    task_testunseen_class=all_class[int(np.sum(args.task_split[:task])):]\n",
    "    print('current_task_class'+str(task_testseen_class))\n",
    "    print('task_testseen_class: '+str(task_testseen_class.shape))\n",
    "    print('task_testunseen_class: '+str(task_testunseen_class.shape))\n",
    "\n",
    "    feature=[]\n",
    "    labels=[]\n",
    "\n",
    "    # for the seen class train data\n",
    "    for i in current_task_class:\n",
    "        indx=np.where(seentrain_data[1]==i)[0]\n",
    "        feature.append(seentrain_data[0][indx])\n",
    "        labels.append(seentrain_data[1][indx])\n",
    "    task_seentrain_data=[torch.from_numpy(np.vstack(feature)),torch.from_numpy(np.hstack(labels).squeeze())]\n",
    "\n",
    "    # for the seen class train data \n",
    "\n",
    "    feature=[]\n",
    "    labels=[]\n",
    "\n",
    "    # for the seen class train data\n",
    "    for i in task_testseen_class:\n",
    "        indx=np.where(seentest_data[1]==i)[0]\n",
    "        feature.append(seentest_data[0][indx])\n",
    "        labels.append(seentest_data[1][indx])\n",
    "    task_seentest_data=[torch.from_numpy(np.vstack(feature)),torch.from_numpy(np.hstack(labels).squeeze())]\n",
    "\n",
    "    feature=[]\n",
    "    labels=[]\n",
    "\n",
    "    # for the test data that are remaining from the seen class\n",
    "    \n",
    "    if task<args.task:\n",
    "        for i in task_testunseen_class:\n",
    "            indx=np.where(Label==i)[0]\n",
    "            feature.append(Data[indx])\n",
    "            labels.append(Label[indx])  \n",
    "        task_unseentest_data=[torch.from_numpy(np.vstack(feature)),torch.from_numpy(np.hstack(labels).squeeze())]\n",
    "    else:\n",
    "        task_unseentest_data=[np.array([]),np.array([])]\n",
    "    \n",
    "    return task_seentrain_data,task_seentest_data,task_unseentest_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d80676",
   "metadata": {},
   "source": [
    "# ZSL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f2db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassNormalization(nn.Module):\n",
    "    \n",
    "    def __init__(self, feat_dim: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.running_mean = nn.Parameter(torch.zeros(feat_dim), requires_grad=False)\n",
    "        self.running_var = nn.Parameter(torch.ones(feat_dim), requires_grad=False)\n",
    "    \n",
    "    def forward(self, class_feats):\n",
    "        \n",
    "        if self.training:\n",
    "            batch_mean = class_feats.mean(dim=0)\n",
    "            batch_var = class_feats.var(dim=0)\n",
    "            \n",
    "            # Normalizing the batch\n",
    "            result = (class_feats - batch_mean.unsqueeze(0)) / (batch_var.unsqueeze(0) + 1e-5)\n",
    "            \n",
    "            # Updating the running mean/std\n",
    "            self.running_mean.data = 0.9 * self.running_mean.data + 0.1 * batch_mean.detach()\n",
    "            self.running_var.data = 0.9 * self.running_var.data + 0.1 * batch_var.detach()\n",
    "        else:\n",
    "            # Using accumulated statistics\n",
    "            # Attention! For the test inference, we cant use batch-wise statistics,\n",
    "            # only the accumulated ones. Otherwise, it will be quite transductive\n",
    "            result = (class_feats - self.running_mean.unsqueeze(0)) / (self.running_var.unsqueeze(0) + 1e-5)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6bba574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZSLModel(nn.Module):\n",
    "    def __init__(self, attr_dim: int, hid_dim: int, proto_dim: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Attribute to Feature Embedding\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(attr_dim, hid_dim),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(hid_dim, hid_dim),\n",
    "            ClassNormalization(hid_dim),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            ClassNormalization(hid_dim),\n",
    "            nn.Linear(hid_dim, proto_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Weight Initialization\n",
    "        weight_var = 1 / (hid_dim * proto_dim)\n",
    "        b = np.sqrt(3 * weight_var)\n",
    "        self.model[-2].weight.data.uniform_(-b, b)\n",
    "        \n",
    "    def forward(self, x, attrs, train=False):\n",
    "        attrs = arn(attrs)\n",
    "        protos = self.model(attrs)\n",
    "        \n",
    "        # Feature-Prototype Combiner \n",
    "        x_ns = 5 * x / x.norm(dim=1, keepdim=True)\n",
    "        protos_ns = 5 * protos / protos.norm(dim=1, keepdim=True)\n",
    "        logits = x_ns @ protos_ns.t()\n",
    "        \n",
    "        x_nss = 1.0 * x / x.norm(dim=1, keepdim=True)\n",
    "        protos_nss = 1.0 * protos / protos.norm(dim=1, keepdim=True)\n",
    "        logits_nn = x_nss @ protos_nss.t()\n",
    "        \n",
    "        if train:\n",
    "            return logits, protos, logits_nn\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d61a76",
   "metadata": {},
   "source": [
    "# Function for Training The Model Task-Wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11a2f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_circle1 = CircleLoss(m=0.4, gamma=0.5)\n",
    "\n",
    "def do_learning(net, optimizer, task, epoch):\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    for (feats_s, targets_s) in train_dataloader:\n",
    "        attrs=attributes[task_seen_class]\n",
    "        attrs_s=attributes[task_seen_class]\n",
    "        \n",
    "                \n",
    "        if task > 1:\n",
    "            feats, targets = er_mem.reservoir_mem_select_data(torch.tensor(feats_s), torch.tensor(targets_s))\n",
    "        else:\n",
    "            feats, targets = feats_s, targets_s\n",
    "        \n",
    "        feats, targets = feats.to(DEVICE), targets.to(DEVICE) \n",
    "        \n",
    "        N, D = feats.shape\n",
    "        C, K = attrs_s.cpu().numpy().shape\n",
    "                \n",
    "               \n",
    "        logits, proto_s, logits_nn = net(feats, attrs, True)\n",
    "        \n",
    "        targets_one_hot = F.one_hot(targets, C)\n",
    "        \n",
    "        sp_bool = targets_one_hot[:] == 1\n",
    "        sn_bool = targets_one_hot[:] != 1\n",
    "        \n",
    "        loss_circle = torch.mean(loss_circle1(sp_bool, sn_bool, logits=logits_nn, N=N, C=C))\n",
    "        \n",
    "        loss = F.cross_entropy(logits, targets) + loss_circle * 1.2\n",
    "        \n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch == args.iterations - 1:\n",
    "            with torch.no_grad():\n",
    "                er_mem.reservoir_mem_update(feats_s.numpy(), targets_s.numpy())\n",
    "\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454095f9",
   "metadata": {},
   "source": [
    "# Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e6b902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<=============== Training Samples %s===============>\n",
      "\n",
      "<=============== Training task 0===============>\n",
      "current_task_class[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46]\n",
      "task_testseen_class: (47,)\n",
      "task_testunseen_class: (670,)\n",
      "[ Epoch: 0  TLoss: 6.510    Best_HMean:  0.039 ACC_seen: 0.336, ACC_unseen: 0.021\n",
      "[ Epoch: 1  TLoss: 5.860    Best_HMean:  0.057 ACC_seen: 0.388, ACC_unseen: 0.031\n",
      "[ Epoch: 2  TLoss: 5.620    Best_HMean:  0.072 ACC_seen: 0.460, ACC_unseen: 0.039\n",
      "[ Epoch: 3  TLoss: 5.357    Best_HMean:  0.076 ACC_seen: 0.445, ACC_unseen: 0.042\n",
      "[ Epoch: 4  TLoss: 5.287    Best_HMean:  0.087 ACC_seen: 0.476, ACC_unseen: 0.048\n",
      "[ Epoch: 5  TLoss: 5.217    Best_HMean:  0.104 ACC_seen: 0.475, ACC_unseen: 0.058\n",
      "[ Epoch: 6  TLoss: 5.117    Best_HMean:  0.118 ACC_seen: 0.450, ACC_unseen: 0.068\n",
      "[ Epoch: 7  TLoss: 5.002    Best_HMean:  0.126 ACC_seen: 0.362, ACC_unseen: 0.077\n",
      "[ Epoch: 8  TLoss: 5.008    Best_HMean:  0.126 ACC_seen: 0.276, ACC_unseen: 0.081\n",
      "[ Epoch: 9  TLoss: 4.945    Best_HMean:  0.126 ACC_seen: 0.241, ACC_unseen: 0.085\n",
      "[ Epoch: 10  TLoss: 4.947    Best_HMean:  0.126 ACC_seen: 0.192, ACC_unseen: 0.084\n",
      "[ Epoch: 11  TLoss: 4.891    Best_HMean:  0.126 ACC_seen: 0.175, ACC_unseen: 0.084\n",
      "[ Epoch: 12  TLoss: 4.881    Best_HMean:  0.126 ACC_seen: 0.132, ACC_unseen: 0.081\n",
      "[ Epoch: 13  TLoss: 4.836    Best_HMean:  0.126 ACC_seen: 0.126, ACC_unseen: 0.081\n",
      "[ Epoch: 14  TLoss: 4.850    Best_HMean:  0.126 ACC_seen: 0.121, ACC_unseen: 0.080\n",
      "[ Epoch: 15  TLoss: 4.845    Best_HMean:  0.126 ACC_seen: 0.105, ACC_unseen: 0.080\n",
      "[ Epoch: 16  TLoss: 4.797    Best_HMean:  0.126 ACC_seen: 0.121, ACC_unseen: 0.078\n",
      "[ Epoch: 17  TLoss: 4.776    Best_HMean:  0.126 ACC_seen: 0.117, ACC_unseen: 0.079\n",
      "[ Epoch: 18  TLoss: 4.797    Best_HMean:  0.126 ACC_seen: 0.094, ACC_unseen: 0.078\n",
      "[ Epoch: 19  TLoss: 4.768    Best_HMean:  0.126 ACC_seen: 0.096, ACC_unseen: 0.077\n",
      "[ Epoch: 20  TLoss: 4.754    Best_HMean:  0.126 ACC_seen: 0.091, ACC_unseen: 0.078\n",
      "[ Epoch: 21  TLoss: 4.749    Best_HMean:  0.126 ACC_seen: 0.082, ACC_unseen: 0.078\n",
      "[ Epoch: 22  TLoss: 4.753    Best_HMean:  0.126 ACC_seen: 0.078, ACC_unseen: 0.079\n",
      "[ Epoch: 23  TLoss: 4.746    Best_HMean:  0.126 ACC_seen: 0.089, ACC_unseen: 0.078\n",
      "[ Epoch: 24  TLoss: 4.750    Best_HMean:  0.126 ACC_seen: 0.093, ACC_unseen: 0.077\n",
      "[ Epoch: 25  TLoss: 4.718    Best_HMean:  0.126 ACC_seen: 0.096, ACC_unseen: 0.077\n",
      "[ Epoch: 26  TLoss: 4.723    Best_HMean:  0.126 ACC_seen: 0.096, ACC_unseen: 0.077\n",
      "[ Epoch: 27  TLoss: 4.725    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 28  TLoss: 4.722    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.078\n",
      "[ Epoch: 29  TLoss: 4.723    Best_HMean:  0.126 ACC_seen: 0.077, ACC_unseen: 0.078\n",
      "[ Epoch: 30  TLoss: 4.714    Best_HMean:  0.126 ACC_seen: 0.077, ACC_unseen: 0.077\n",
      "[ Epoch: 31  TLoss: 4.693    Best_HMean:  0.126 ACC_seen: 0.077, ACC_unseen: 0.077\n",
      "[ Epoch: 32  TLoss: 4.692    Best_HMean:  0.126 ACC_seen: 0.077, ACC_unseen: 0.077\n",
      "[ Epoch: 33  TLoss: 4.706    Best_HMean:  0.126 ACC_seen: 0.077, ACC_unseen: 0.077\n",
      "[ Epoch: 34  TLoss: 4.711    Best_HMean:  0.126 ACC_seen: 0.077, ACC_unseen: 0.077\n",
      "[ Epoch: 35  TLoss: 4.708    Best_HMean:  0.126 ACC_seen: 0.077, ACC_unseen: 0.077\n",
      "[ Epoch: 36  TLoss: 4.712    Best_HMean:  0.126 ACC_seen: 0.077, ACC_unseen: 0.077\n",
      "[ Epoch: 37  TLoss: 4.723    Best_HMean:  0.126 ACC_seen: 0.077, ACC_unseen: 0.076\n",
      "[ Epoch: 38  TLoss: 4.705    Best_HMean:  0.126 ACC_seen: 0.077, ACC_unseen: 0.077\n",
      "[ Epoch: 39  TLoss: 4.705    Best_HMean:  0.126 ACC_seen: 0.077, ACC_unseen: 0.077\n",
      "[ Epoch: 40  TLoss: 4.715    Best_HMean:  0.126 ACC_seen: 0.081, ACC_unseen: 0.076\n",
      "[ Epoch: 41  TLoss: 4.709    Best_HMean:  0.126 ACC_seen: 0.081, ACC_unseen: 0.077\n",
      "[ Epoch: 42  TLoss: 4.717    Best_HMean:  0.126 ACC_seen: 0.081, ACC_unseen: 0.076\n",
      "[ Epoch: 43  TLoss: 4.694    Best_HMean:  0.126 ACC_seen: 0.081, ACC_unseen: 0.076\n",
      "[ Epoch: 44  TLoss: 4.710    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 45  TLoss: 4.704    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 46  TLoss: 4.719    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 47  TLoss: 4.709    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 48  TLoss: 4.713    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 49  TLoss: 4.719    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 50  TLoss: 4.700    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 51  TLoss: 4.704    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 52  TLoss: 4.715    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 53  TLoss: 4.695    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 54  TLoss: 4.700    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 55  TLoss: 4.725    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 56  TLoss: 4.699    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 57  TLoss: 4.698    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 58  TLoss: 4.703    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 59  TLoss: 4.704    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 60  TLoss: 4.693    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 61  TLoss: 4.697    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 62  TLoss: 4.723    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 63  TLoss: 4.709    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 64  TLoss: 4.692    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 65  TLoss: 4.705    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 66  TLoss: 4.690    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 67  TLoss: 4.703    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 68  TLoss: 4.715    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 69  TLoss: 4.702    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 70  TLoss: 4.697    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 71  TLoss: 4.689    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 72  TLoss: 4.708    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 73  TLoss: 4.691    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 74  TLoss: 4.724    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 75  TLoss: 4.710    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 76  TLoss: 4.693    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 77  TLoss: 4.694    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 78  TLoss: 4.715    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 79  TLoss: 4.705    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 80  TLoss: 4.691    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 81  TLoss: 4.711    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 82  TLoss: 4.703    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 83  TLoss: 4.701    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 84  TLoss: 4.688    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 85  TLoss: 4.708    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 86  TLoss: 4.694    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 87  TLoss: 4.715    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 88  TLoss: 4.696    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 89  TLoss: 4.713    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 90  TLoss: 4.694    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 91  TLoss: 4.695    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 92  TLoss: 4.700    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 93  TLoss: 4.697    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 94  TLoss: 4.707    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 95  TLoss: 4.703    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 96  TLoss: 4.705    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 97  TLoss: 4.686    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 98  TLoss: 4.705    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[ Epoch: 99  TLoss: 4.705    Best_HMean:  0.126 ACC_seen: 0.092, ACC_unseen: 0.077\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576]]\n",
      "\n",
      "<=============== Training task 1===============>\n",
      "current_task_class[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93]\n",
      "task_testseen_class: (94,)\n",
      "task_testunseen_class: (623,)\n",
      "[ Epoch: 0  TLoss: 6.306    Best_HMean:  0.151 ACC_seen: 0.266, ACC_unseen: 0.106\n",
      "[ Epoch: 1  TLoss: 6.043    Best_HMean:  0.164 ACC_seen: 0.279, ACC_unseen: 0.116\n",
      "[ Epoch: 2  TLoss: 5.910    Best_HMean:  0.164 ACC_seen: 0.284, ACC_unseen: 0.114\n",
      "[ Epoch: 3  TLoss: 5.862    Best_HMean:  0.164 ACC_seen: 0.276, ACC_unseen: 0.116\n",
      "[ Epoch: 4  TLoss: 5.804    Best_HMean:  0.164 ACC_seen: 0.257, ACC_unseen: 0.116\n",
      "[ Epoch: 5  TLoss: 5.751    Best_HMean:  0.164 ACC_seen: 0.240, ACC_unseen: 0.116\n",
      "[ Epoch: 6  TLoss: 5.742    Best_HMean:  0.164 ACC_seen: 0.239, ACC_unseen: 0.117\n",
      "[ Epoch: 7  TLoss: 5.699    Best_HMean:  0.164 ACC_seen: 0.215, ACC_unseen: 0.119\n",
      "[ Epoch: 8  TLoss: 5.683    Best_HMean:  0.164 ACC_seen: 0.198, ACC_unseen: 0.120\n",
      "[ Epoch: 9  TLoss: 5.666    Best_HMean:  0.164 ACC_seen: 0.188, ACC_unseen: 0.121\n",
      "[ Epoch: 10  TLoss: 5.665    Best_HMean:  0.164 ACC_seen: 0.183, ACC_unseen: 0.121\n",
      "[ Epoch: 11  TLoss: 5.662    Best_HMean:  0.164 ACC_seen: 0.181, ACC_unseen: 0.121\n",
      "[ Epoch: 12  TLoss: 5.650    Best_HMean:  0.164 ACC_seen: 0.168, ACC_unseen: 0.122\n",
      "[ Epoch: 13  TLoss: 5.635    Best_HMean:  0.164 ACC_seen: 0.174, ACC_unseen: 0.122\n",
      "[ Epoch: 14  TLoss: 5.644    Best_HMean:  0.164 ACC_seen: 0.159, ACC_unseen: 0.122\n",
      "[ Epoch: 15  TLoss: 5.647    Best_HMean:  0.164 ACC_seen: 0.155, ACC_unseen: 0.119\n",
      "[ Epoch: 16  TLoss: 5.638    Best_HMean:  0.164 ACC_seen: 0.157, ACC_unseen: 0.120\n",
      "[ Epoch: 17  TLoss: 5.638    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 18  TLoss: 5.632    Best_HMean:  0.164 ACC_seen: 0.148, ACC_unseen: 0.122\n",
      "[ Epoch: 19  TLoss: 5.623    Best_HMean:  0.164 ACC_seen: 0.146, ACC_unseen: 0.122\n",
      "[ Epoch: 20  TLoss: 5.634    Best_HMean:  0.164 ACC_seen: 0.154, ACC_unseen: 0.122\n",
      "[ Epoch: 21  TLoss: 5.639    Best_HMean:  0.164 ACC_seen: 0.150, ACC_unseen: 0.121\n",
      "[ Epoch: 22  TLoss: 5.633    Best_HMean:  0.164 ACC_seen: 0.145, ACC_unseen: 0.122\n",
      "[ Epoch: 23  TLoss: 5.626    Best_HMean:  0.164 ACC_seen: 0.151, ACC_unseen: 0.121\n",
      "[ Epoch: 24  TLoss: 5.622    Best_HMean:  0.164 ACC_seen: 0.155, ACC_unseen: 0.121\n",
      "[ Epoch: 25  TLoss: 5.614    Best_HMean:  0.164 ACC_seen: 0.152, ACC_unseen: 0.121\n",
      "[ Epoch: 26  TLoss: 5.619    Best_HMean:  0.164 ACC_seen: 0.152, ACC_unseen: 0.121\n",
      "[ Epoch: 27  TLoss: 5.620    Best_HMean:  0.164 ACC_seen: 0.147, ACC_unseen: 0.122\n",
      "[ Epoch: 28  TLoss: 5.626    Best_HMean:  0.164 ACC_seen: 0.144, ACC_unseen: 0.121\n",
      "[ Epoch: 29  TLoss: 5.612    Best_HMean:  0.164 ACC_seen: 0.148, ACC_unseen: 0.121\n",
      "[ Epoch: 30  TLoss: 5.615    Best_HMean:  0.164 ACC_seen: 0.148, ACC_unseen: 0.121\n",
      "[ Epoch: 31  TLoss: 5.621    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 32  TLoss: 5.612    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 33  TLoss: 5.616    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 34  TLoss: 5.618    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 35  TLoss: 5.611    Best_HMean:  0.164 ACC_seen: 0.152, ACC_unseen: 0.121\n",
      "[ Epoch: 36  TLoss: 5.627    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 37  TLoss: 5.609    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 38  TLoss: 5.621    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 39  TLoss: 5.619    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 40  TLoss: 5.619    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 41  TLoss: 5.615    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 42  TLoss: 5.619    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 43  TLoss: 5.617    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 44  TLoss: 5.620    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 45  TLoss: 5.616    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 46  TLoss: 5.612    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 47  TLoss: 5.618    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 48  TLoss: 5.616    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 49  TLoss: 5.617    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 50  TLoss: 5.621    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 51  TLoss: 5.611    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 52  TLoss: 5.615    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 53  TLoss: 5.615    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 54  TLoss: 5.619    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.121\n",
      "[ Epoch: 55  TLoss: 5.619    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 56  TLoss: 5.617    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 57  TLoss: 5.614    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 58  TLoss: 5.611    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 59  TLoss: 5.613    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 60  TLoss: 5.612    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 61  TLoss: 5.612    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 62  TLoss: 5.613    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 63  TLoss: 5.613    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 64  TLoss: 5.612    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 65  TLoss: 5.623    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 66  TLoss: 5.613    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 67  TLoss: 5.615    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 68  TLoss: 5.608    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 69  TLoss: 5.614    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 70  TLoss: 5.612    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 71  TLoss: 5.621    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 72  TLoss: 5.611    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 73  TLoss: 5.611    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 74  TLoss: 5.618    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 75  TLoss: 5.613    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 76  TLoss: 5.613    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 77  TLoss: 5.617    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 78  TLoss: 5.610    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 79  TLoss: 5.606    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 80  TLoss: 5.608    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 81  TLoss: 5.608    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 82  TLoss: 5.614    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 83  TLoss: 5.613    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 84  TLoss: 5.613    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 85  TLoss: 5.606    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 86  TLoss: 5.623    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 87  TLoss: 5.612    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 88  TLoss: 5.616    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 89  TLoss: 5.615    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 90  TLoss: 5.607    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 91  TLoss: 5.615    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 92  TLoss: 5.617    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 93  TLoss: 5.617    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 94  TLoss: 5.612    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 95  TLoss: 5.617    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 96  TLoss: 5.615    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 97  TLoss: 5.608    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 98  TLoss: 5.618    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[ Epoch: 99  TLoss: 5.667    Best_HMean:  0.164 ACC_seen: 0.156, ACC_unseen: 0.122\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735]]\n",
      "\n",
      "<=============== Training task 2===============>\n",
      "current_task_class[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140]\n",
      "task_testseen_class: (141,)\n",
      "task_testunseen_class: (576,)\n",
      "[ Epoch: 0  TLoss: 6.694    Best_HMean:  0.174 ACC_seen: 0.223, ACC_unseen: 0.142\n",
      "[ Epoch: 1  TLoss: 6.530    Best_HMean:  0.182 ACC_seen: 0.245, ACC_unseen: 0.145\n",
      "[ Epoch: 2  TLoss: 6.498    Best_HMean:  0.184 ACC_seen: 0.238, ACC_unseen: 0.150\n",
      "[ Epoch: 3  TLoss: 6.406    Best_HMean:  0.184 ACC_seen: 0.222, ACC_unseen: 0.154\n",
      "[ Epoch: 4  TLoss: 6.370    Best_HMean:  0.184 ACC_seen: 0.225, ACC_unseen: 0.155\n",
      "[ Epoch: 5  TLoss: 6.343    Best_HMean:  0.184 ACC_seen: 0.234, ACC_unseen: 0.151\n",
      "[ Epoch: 6  TLoss: 6.335    Best_HMean:  0.189 ACC_seen: 0.248, ACC_unseen: 0.152\n",
      "[ Epoch: 7  TLoss: 6.311    Best_HMean:  0.189 ACC_seen: 0.235, ACC_unseen: 0.155\n",
      "[ Epoch: 8  TLoss: 6.271    Best_HMean:  0.189 ACC_seen: 0.233, ACC_unseen: 0.157\n",
      "[ Epoch: 9  TLoss: 6.284    Best_HMean:  0.189 ACC_seen: 0.227, ACC_unseen: 0.157\n",
      "[ Epoch: 10  TLoss: 6.271    Best_HMean:  0.189 ACC_seen: 0.215, ACC_unseen: 0.157\n",
      "[ Epoch: 11  TLoss: 6.252    Best_HMean:  0.189 ACC_seen: 0.213, ACC_unseen: 0.156\n",
      "[ Epoch: 12  TLoss: 6.233    Best_HMean:  0.189 ACC_seen: 0.217, ACC_unseen: 0.160\n",
      "[ Epoch: 13  TLoss: 6.253    Best_HMean:  0.189 ACC_seen: 0.203, ACC_unseen: 0.158\n",
      "[ Epoch: 14  TLoss: 6.253    Best_HMean:  0.189 ACC_seen: 0.199, ACC_unseen: 0.157\n",
      "[ Epoch: 15  TLoss: 6.255    Best_HMean:  0.189 ACC_seen: 0.201, ACC_unseen: 0.156\n",
      "[ Epoch: 16  TLoss: 6.237    Best_HMean:  0.189 ACC_seen: 0.197, ACC_unseen: 0.158\n",
      "[ Epoch: 17  TLoss: 6.228    Best_HMean:  0.189 ACC_seen: 0.213, ACC_unseen: 0.158\n",
      "[ Epoch: 18  TLoss: 6.242    Best_HMean:  0.189 ACC_seen: 0.207, ACC_unseen: 0.157\n",
      "[ Epoch: 19  TLoss: 6.242    Best_HMean:  0.189 ACC_seen: 0.186, ACC_unseen: 0.157\n",
      "[ Epoch: 20  TLoss: 6.209    Best_HMean:  0.189 ACC_seen: 0.190, ACC_unseen: 0.158\n",
      "[ Epoch: 21  TLoss: 6.216    Best_HMean:  0.189 ACC_seen: 0.194, ACC_unseen: 0.159\n",
      "[ Epoch: 22  TLoss: 6.214    Best_HMean:  0.189 ACC_seen: 0.196, ACC_unseen: 0.158\n",
      "[ Epoch: 23  TLoss: 6.226    Best_HMean:  0.189 ACC_seen: 0.190, ACC_unseen: 0.159\n",
      "[ Epoch: 24  TLoss: 6.225    Best_HMean:  0.189 ACC_seen: 0.191, ACC_unseen: 0.157\n",
      "[ Epoch: 25  TLoss: 6.208    Best_HMean:  0.189 ACC_seen: 0.189, ACC_unseen: 0.156\n",
      "[ Epoch: 26  TLoss: 6.221    Best_HMean:  0.189 ACC_seen: 0.188, ACC_unseen: 0.157\n",
      "[ Epoch: 27  TLoss: 6.222    Best_HMean:  0.189 ACC_seen: 0.186, ACC_unseen: 0.158\n",
      "[ Epoch: 28  TLoss: 6.211    Best_HMean:  0.189 ACC_seen: 0.185, ACC_unseen: 0.157\n",
      "[ Epoch: 29  TLoss: 6.196    Best_HMean:  0.189 ACC_seen: 0.187, ACC_unseen: 0.157\n",
      "[ Epoch: 30  TLoss: 6.211    Best_HMean:  0.189 ACC_seen: 0.189, ACC_unseen: 0.156\n",
      "[ Epoch: 31  TLoss: 6.209    Best_HMean:  0.189 ACC_seen: 0.196, ACC_unseen: 0.156\n",
      "[ Epoch: 32  TLoss: 6.202    Best_HMean:  0.189 ACC_seen: 0.196, ACC_unseen: 0.156\n",
      "[ Epoch: 33  TLoss: 6.199    Best_HMean:  0.189 ACC_seen: 0.196, ACC_unseen: 0.155\n",
      "[ Epoch: 34  TLoss: 6.198    Best_HMean:  0.189 ACC_seen: 0.194, ACC_unseen: 0.155\n",
      "[ Epoch: 35  TLoss: 6.199    Best_HMean:  0.189 ACC_seen: 0.191, ACC_unseen: 0.155\n",
      "[ Epoch: 36  TLoss: 6.190    Best_HMean:  0.189 ACC_seen: 0.194, ACC_unseen: 0.155\n",
      "[ Epoch: 37  TLoss: 6.194    Best_HMean:  0.189 ACC_seen: 0.194, ACC_unseen: 0.155\n",
      "[ Epoch: 38  TLoss: 6.202    Best_HMean:  0.189 ACC_seen: 0.195, ACC_unseen: 0.155\n",
      "[ Epoch: 39  TLoss: 6.193    Best_HMean:  0.189 ACC_seen: 0.196, ACC_unseen: 0.155\n",
      "[ Epoch: 40  TLoss: 6.196    Best_HMean:  0.189 ACC_seen: 0.193, ACC_unseen: 0.156\n",
      "[ Epoch: 41  TLoss: 6.194    Best_HMean:  0.189 ACC_seen: 0.186, ACC_unseen: 0.156\n",
      "[ Epoch: 42  TLoss: 6.204    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 43  TLoss: 6.187    Best_HMean:  0.189 ACC_seen: 0.189, ACC_unseen: 0.156\n",
      "[ Epoch: 44  TLoss: 6.195    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 45  TLoss: 6.204    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 46  TLoss: 6.195    Best_HMean:  0.189 ACC_seen: 0.192, ACC_unseen: 0.156\n",
      "[ Epoch: 47  TLoss: 6.188    Best_HMean:  0.189 ACC_seen: 0.186, ACC_unseen: 0.157\n",
      "[ Epoch: 48  TLoss: 6.186    Best_HMean:  0.189 ACC_seen: 0.187, ACC_unseen: 0.157\n",
      "[ Epoch: 49  TLoss: 6.202    Best_HMean:  0.189 ACC_seen: 0.191, ACC_unseen: 0.157\n",
      "[ Epoch: 50  TLoss: 6.196    Best_HMean:  0.189 ACC_seen: 0.191, ACC_unseen: 0.157\n",
      "[ Epoch: 51  TLoss: 6.186    Best_HMean:  0.189 ACC_seen: 0.191, ACC_unseen: 0.157\n",
      "[ Epoch: 52  TLoss: 6.190    Best_HMean:  0.189 ACC_seen: 0.198, ACC_unseen: 0.157\n",
      "[ Epoch: 53  TLoss: 6.187    Best_HMean:  0.189 ACC_seen: 0.198, ACC_unseen: 0.157\n",
      "[ Epoch: 54  TLoss: 6.185    Best_HMean:  0.189 ACC_seen: 0.198, ACC_unseen: 0.157\n",
      "[ Epoch: 55  TLoss: 6.194    Best_HMean:  0.189 ACC_seen: 0.198, ACC_unseen: 0.156\n",
      "[ Epoch: 56  TLoss: 6.206    Best_HMean:  0.189 ACC_seen: 0.194, ACC_unseen: 0.156\n",
      "[ Epoch: 57  TLoss: 6.199    Best_HMean:  0.189 ACC_seen: 0.194, ACC_unseen: 0.156\n",
      "[ Epoch: 58  TLoss: 6.192    Best_HMean:  0.189 ACC_seen: 0.187, ACC_unseen: 0.156\n",
      "[ Epoch: 59  TLoss: 6.198    Best_HMean:  0.189 ACC_seen: 0.187, ACC_unseen: 0.157\n",
      "[ Epoch: 60  TLoss: 6.191    Best_HMean:  0.189 ACC_seen: 0.187, ACC_unseen: 0.157\n",
      "[ Epoch: 61  TLoss: 6.192    Best_HMean:  0.189 ACC_seen: 0.187, ACC_unseen: 0.157\n",
      "[ Epoch: 62  TLoss: 6.179    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 63  TLoss: 6.201    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 64  TLoss: 6.195    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 65  TLoss: 6.188    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 66  TLoss: 6.195    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 67  TLoss: 6.207    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 68  TLoss: 6.182    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 69  TLoss: 6.192    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 70  TLoss: 6.198    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 71  TLoss: 6.202    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 72  TLoss: 6.196    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 73  TLoss: 6.191    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 74  TLoss: 6.183    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 75  TLoss: 6.184    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.157\n",
      "[ Epoch: 76  TLoss: 6.195    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 77  TLoss: 6.191    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 78  TLoss: 6.198    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 79  TLoss: 6.201    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 80  TLoss: 6.203    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 81  TLoss: 6.195    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 82  TLoss: 6.194    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 83  TLoss: 6.196    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 84  TLoss: 6.200    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 85  TLoss: 6.191    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 86  TLoss: 6.195    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 87  TLoss: 6.196    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 88  TLoss: 6.195    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 89  TLoss: 6.184    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 90  TLoss: 6.190    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 91  TLoss: 6.199    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 92  TLoss: 6.194    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 93  TLoss: 6.184    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 94  TLoss: 6.191    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 95  TLoss: 6.188    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 96  TLoss: 6.178    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 97  TLoss: 6.194    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 98  TLoss: 6.186    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[ Epoch: 99  TLoss: 6.213    Best_HMean:  0.189 ACC_seen: 0.183, ACC_unseen: 0.156\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233]]\n",
      "\n",
      "<=============== Training task 3===============>\n",
      "current_task_class[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188]\n",
      "task_testseen_class: (189,)\n",
      "task_testunseen_class: (528,)\n",
      "[ Epoch: 0  TLoss: 6.819    Best_HMean:  0.199 ACC_seen: 0.241, ACC_unseen: 0.170\n",
      "[ Epoch: 1  TLoss: 6.809    Best_HMean:  0.208 ACC_seen: 0.257, ACC_unseen: 0.175\n",
      "[ Epoch: 2  TLoss: 6.744    Best_HMean:  0.213 ACC_seen: 0.262, ACC_unseen: 0.180\n",
      "[ Epoch: 3  TLoss: 6.729    Best_HMean:  0.217 ACC_seen: 0.269, ACC_unseen: 0.182\n",
      "[ Epoch: 4  TLoss: 6.709    Best_HMean:  0.217 ACC_seen: 0.265, ACC_unseen: 0.179\n",
      "[ Epoch: 5  TLoss: 6.714    Best_HMean:  0.217 ACC_seen: 0.260, ACC_unseen: 0.182\n",
      "[ Epoch: 6  TLoss: 6.690    Best_HMean:  0.217 ACC_seen: 0.261, ACC_unseen: 0.184\n",
      "[ Epoch: 7  TLoss: 6.663    Best_HMean:  0.217 ACC_seen: 0.267, ACC_unseen: 0.183\n",
      "[ Epoch: 8  TLoss: 6.681    Best_HMean:  0.217 ACC_seen: 0.248, ACC_unseen: 0.184\n",
      "[ Epoch: 9  TLoss: 6.689    Best_HMean:  0.217 ACC_seen: 0.242, ACC_unseen: 0.183\n",
      "[ Epoch: 10  TLoss: 6.696    Best_HMean:  0.217 ACC_seen: 0.232, ACC_unseen: 0.183\n",
      "[ Epoch: 11  TLoss: 6.661    Best_HMean:  0.217 ACC_seen: 0.229, ACC_unseen: 0.182\n",
      "[ Epoch: 12  TLoss: 6.677    Best_HMean:  0.217 ACC_seen: 0.239, ACC_unseen: 0.189\n",
      "[ Epoch: 13  TLoss: 6.642    Best_HMean:  0.217 ACC_seen: 0.226, ACC_unseen: 0.188\n",
      "[ Epoch: 14  TLoss: 6.661    Best_HMean:  0.217 ACC_seen: 0.229, ACC_unseen: 0.187\n",
      "[ Epoch: 15  TLoss: 6.665    Best_HMean:  0.217 ACC_seen: 0.220, ACC_unseen: 0.187\n",
      "[ Epoch: 16  TLoss: 6.656    Best_HMean:  0.217 ACC_seen: 0.221, ACC_unseen: 0.187\n",
      "[ Epoch: 17  TLoss: 6.666    Best_HMean:  0.217 ACC_seen: 0.215, ACC_unseen: 0.186\n",
      "[ Epoch: 18  TLoss: 6.635    Best_HMean:  0.217 ACC_seen: 0.216, ACC_unseen: 0.184\n",
      "[ Epoch: 19  TLoss: 6.646    Best_HMean:  0.217 ACC_seen: 0.218, ACC_unseen: 0.185\n",
      "[ Epoch: 20  TLoss: 6.656    Best_HMean:  0.217 ACC_seen: 0.217, ACC_unseen: 0.188\n",
      "[ Epoch: 21  TLoss: 6.622    Best_HMean:  0.217 ACC_seen: 0.217, ACC_unseen: 0.187\n",
      "[ Epoch: 22  TLoss: 6.664    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.183\n",
      "[ Epoch: 23  TLoss: 6.630    Best_HMean:  0.217 ACC_seen: 0.209, ACC_unseen: 0.188\n",
      "[ Epoch: 24  TLoss: 6.644    Best_HMean:  0.217 ACC_seen: 0.202, ACC_unseen: 0.191\n",
      "[ Epoch: 25  TLoss: 6.626    Best_HMean:  0.217 ACC_seen: 0.202, ACC_unseen: 0.190\n",
      "[ Epoch: 26  TLoss: 6.644    Best_HMean:  0.217 ACC_seen: 0.210, ACC_unseen: 0.191\n",
      "[ Epoch: 27  TLoss: 6.616    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.189\n",
      "[ Epoch: 28  TLoss: 6.624    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.190\n",
      "[ Epoch: 29  TLoss: 6.627    Best_HMean:  0.217 ACC_seen: 0.214, ACC_unseen: 0.190\n",
      "[ Epoch: 30  TLoss: 6.626    Best_HMean:  0.217 ACC_seen: 0.214, ACC_unseen: 0.190\n",
      "[ Epoch: 31  TLoss: 6.599    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.188\n",
      "[ Epoch: 32  TLoss: 6.612    Best_HMean:  0.217 ACC_seen: 0.208, ACC_unseen: 0.189\n",
      "[ Epoch: 33  TLoss: 6.612    Best_HMean:  0.217 ACC_seen: 0.204, ACC_unseen: 0.188\n",
      "[ Epoch: 34  TLoss: 6.621    Best_HMean:  0.217 ACC_seen: 0.207, ACC_unseen: 0.189\n",
      "[ Epoch: 35  TLoss: 6.615    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.189\n",
      "[ Epoch: 36  TLoss: 6.606    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 37  TLoss: 6.618    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 38  TLoss: 6.615    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 39  TLoss: 6.624    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.188\n",
      "[ Epoch: 40  TLoss: 6.606    Best_HMean:  0.217 ACC_seen: 0.210, ACC_unseen: 0.188\n",
      "[ Epoch: 41  TLoss: 6.617    Best_HMean:  0.217 ACC_seen: 0.213, ACC_unseen: 0.189\n",
      "[ Epoch: 42  TLoss: 6.606    Best_HMean:  0.217 ACC_seen: 0.214, ACC_unseen: 0.189\n",
      "[ Epoch: 43  TLoss: 6.612    Best_HMean:  0.217 ACC_seen: 0.209, ACC_unseen: 0.188\n",
      "[ Epoch: 44  TLoss: 6.629    Best_HMean:  0.217 ACC_seen: 0.207, ACC_unseen: 0.187\n",
      "[ Epoch: 45  TLoss: 6.607    Best_HMean:  0.217 ACC_seen: 0.207, ACC_unseen: 0.187\n",
      "[ Epoch: 46  TLoss: 6.597    Best_HMean:  0.217 ACC_seen: 0.209, ACC_unseen: 0.188\n",
      "[ Epoch: 47  TLoss: 6.604    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.187\n",
      "[ Epoch: 48  TLoss: 6.615    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 49  TLoss: 6.596    Best_HMean:  0.217 ACC_seen: 0.213, ACC_unseen: 0.187\n",
      "[ Epoch: 50  TLoss: 6.621    Best_HMean:  0.217 ACC_seen: 0.213, ACC_unseen: 0.187\n",
      "[ Epoch: 51  TLoss: 6.624    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.187\n",
      "[ Epoch: 52  TLoss: 6.603    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.187\n",
      "[ Epoch: 53  TLoss: 6.587    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.187\n",
      "[ Epoch: 54  TLoss: 6.605    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.187\n",
      "[ Epoch: 55  TLoss: 6.602    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.187\n",
      "[ Epoch: 56  TLoss: 6.606    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.186\n",
      "[ Epoch: 57  TLoss: 6.607    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.187\n",
      "[ Epoch: 58  TLoss: 6.592    Best_HMean:  0.217 ACC_seen: 0.213, ACC_unseen: 0.187\n",
      "[ Epoch: 59  TLoss: 6.608    Best_HMean:  0.217 ACC_seen: 0.213, ACC_unseen: 0.187\n",
      "[ Epoch: 60  TLoss: 6.606    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.187\n",
      "[ Epoch: 61  TLoss: 6.610    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.187\n",
      "[ Epoch: 62  TLoss: 6.597    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.187\n",
      "[ Epoch: 63  TLoss: 6.609    Best_HMean:  0.217 ACC_seen: 0.212, ACC_unseen: 0.187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 64  TLoss: 6.614    Best_HMean:  0.217 ACC_seen: 0.210, ACC_unseen: 0.187\n",
      "[ Epoch: 65  TLoss: 6.600    Best_HMean:  0.217 ACC_seen: 0.210, ACC_unseen: 0.187\n",
      "[ Epoch: 66  TLoss: 6.613    Best_HMean:  0.217 ACC_seen: 0.210, ACC_unseen: 0.187\n",
      "[ Epoch: 67  TLoss: 6.596    Best_HMean:  0.217 ACC_seen: 0.210, ACC_unseen: 0.187\n",
      "[ Epoch: 68  TLoss: 6.613    Best_HMean:  0.217 ACC_seen: 0.210, ACC_unseen: 0.187\n",
      "[ Epoch: 69  TLoss: 6.589    Best_HMean:  0.217 ACC_seen: 0.210, ACC_unseen: 0.188\n",
      "[ Epoch: 70  TLoss: 6.591    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 71  TLoss: 6.608    Best_HMean:  0.217 ACC_seen: 0.209, ACC_unseen: 0.187\n",
      "[ Epoch: 72  TLoss: 6.621    Best_HMean:  0.217 ACC_seen: 0.209, ACC_unseen: 0.187\n",
      "[ Epoch: 73  TLoss: 6.603    Best_HMean:  0.217 ACC_seen: 0.209, ACC_unseen: 0.187\n",
      "[ Epoch: 74  TLoss: 6.605    Best_HMean:  0.217 ACC_seen: 0.208, ACC_unseen: 0.187\n",
      "[ Epoch: 75  TLoss: 6.601    Best_HMean:  0.217 ACC_seen: 0.208, ACC_unseen: 0.187\n",
      "[ Epoch: 76  TLoss: 6.608    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 77  TLoss: 6.623    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 78  TLoss: 6.593    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 79  TLoss: 6.608    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 80  TLoss: 6.585    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 81  TLoss: 6.592    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 82  TLoss: 6.601    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 83  TLoss: 6.618    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 84  TLoss: 6.580    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 85  TLoss: 6.595    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 86  TLoss: 6.589    Best_HMean:  0.217 ACC_seen: 0.208, ACC_unseen: 0.187\n",
      "[ Epoch: 87  TLoss: 6.588    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 88  TLoss: 6.602    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 89  TLoss: 6.612    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 90  TLoss: 6.601    Best_HMean:  0.217 ACC_seen: 0.208, ACC_unseen: 0.187\n",
      "[ Epoch: 91  TLoss: 6.630    Best_HMean:  0.217 ACC_seen: 0.208, ACC_unseen: 0.187\n",
      "[ Epoch: 92  TLoss: 6.610    Best_HMean:  0.217 ACC_seen: 0.208, ACC_unseen: 0.187\n",
      "[ Epoch: 93  TLoss: 6.605    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 94  TLoss: 6.585    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 95  TLoss: 6.606    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 96  TLoss: 6.594    Best_HMean:  0.217 ACC_seen: 0.213, ACC_unseen: 0.187\n",
      "[ Epoch: 97  TLoss: 6.608    Best_HMean:  0.217 ACC_seen: 0.213, ACC_unseen: 0.187\n",
      "[ Epoch: 98  TLoss: 6.606    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[ Epoch: 99  TLoss: 6.627    Best_HMean:  0.217 ACC_seen: 0.211, ACC_unseen: 0.187\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233], [0.26659650816827546, 0.1833332416667125, 0.2172605926922656]]\n",
      "\n",
      "<=============== Training task 4===============>\n",
      "current_task_class[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236]\n",
      "task_testseen_class: (237,)\n",
      "task_testunseen_class: (480,)\n",
      "[ Epoch: 0  TLoss: 7.429    Best_HMean:  0.238 ACC_seen: 0.284, ACC_unseen: 0.205\n",
      "[ Epoch: 1  TLoss: 7.298    Best_HMean:  0.240 ACC_seen: 0.290, ACC_unseen: 0.204\n",
      "[ Epoch: 2  TLoss: 7.219    Best_HMean:  0.240 ACC_seen: 0.292, ACC_unseen: 0.204\n",
      "[ Epoch: 3  TLoss: 7.226    Best_HMean:  0.240 ACC_seen: 0.285, ACC_unseen: 0.204\n",
      "[ Epoch: 4  TLoss: 7.173    Best_HMean:  0.240 ACC_seen: 0.278, ACC_unseen: 0.205\n",
      "[ Epoch: 5  TLoss: 7.148    Best_HMean:  0.240 ACC_seen: 0.286, ACC_unseen: 0.202\n",
      "[ Epoch: 6  TLoss: 7.137    Best_HMean:  0.240 ACC_seen: 0.279, ACC_unseen: 0.205\n",
      "[ Epoch: 7  TLoss: 7.095    Best_HMean:  0.240 ACC_seen: 0.281, ACC_unseen: 0.208\n",
      "[ Epoch: 8  TLoss: 7.060    Best_HMean:  0.240 ACC_seen: 0.276, ACC_unseen: 0.211\n",
      "[ Epoch: 9  TLoss: 7.076    Best_HMean:  0.240 ACC_seen: 0.266, ACC_unseen: 0.209\n",
      "[ Epoch: 10  TLoss: 7.084    Best_HMean:  0.240 ACC_seen: 0.271, ACC_unseen: 0.207\n",
      "[ Epoch: 11  TLoss: 7.073    Best_HMean:  0.240 ACC_seen: 0.262, ACC_unseen: 0.211\n",
      "[ Epoch: 12  TLoss: 7.070    Best_HMean:  0.240 ACC_seen: 0.256, ACC_unseen: 0.209\n",
      "[ Epoch: 13  TLoss: 7.028    Best_HMean:  0.240 ACC_seen: 0.256, ACC_unseen: 0.209\n",
      "[ Epoch: 14  TLoss: 7.047    Best_HMean:  0.240 ACC_seen: 0.246, ACC_unseen: 0.213\n",
      "[ Epoch: 15  TLoss: 7.041    Best_HMean:  0.240 ACC_seen: 0.246, ACC_unseen: 0.211\n",
      "[ Epoch: 16  TLoss: 7.036    Best_HMean:  0.240 ACC_seen: 0.241, ACC_unseen: 0.209\n",
      "[ Epoch: 17  TLoss: 7.029    Best_HMean:  0.240 ACC_seen: 0.242, ACC_unseen: 0.211\n",
      "[ Epoch: 18  TLoss: 7.037    Best_HMean:  0.240 ACC_seen: 0.257, ACC_unseen: 0.212\n",
      "[ Epoch: 19  TLoss: 7.011    Best_HMean:  0.240 ACC_seen: 0.261, ACC_unseen: 0.213\n",
      "[ Epoch: 20  TLoss: 7.036    Best_HMean:  0.240 ACC_seen: 0.254, ACC_unseen: 0.213\n",
      "[ Epoch: 21  TLoss: 7.042    Best_HMean:  0.240 ACC_seen: 0.251, ACC_unseen: 0.214\n",
      "[ Epoch: 22  TLoss: 7.011    Best_HMean:  0.240 ACC_seen: 0.239, ACC_unseen: 0.210\n",
      "[ Epoch: 23  TLoss: 7.031    Best_HMean:  0.240 ACC_seen: 0.238, ACC_unseen: 0.210\n",
      "[ Epoch: 24  TLoss: 6.997    Best_HMean:  0.240 ACC_seen: 0.234, ACC_unseen: 0.213\n",
      "[ Epoch: 25  TLoss: 7.022    Best_HMean:  0.240 ACC_seen: 0.233, ACC_unseen: 0.214\n",
      "[ Epoch: 26  TLoss: 7.023    Best_HMean:  0.240 ACC_seen: 0.230, ACC_unseen: 0.214\n",
      "[ Epoch: 27  TLoss: 7.010    Best_HMean:  0.240 ACC_seen: 0.234, ACC_unseen: 0.215\n",
      "[ Epoch: 28  TLoss: 7.004    Best_HMean:  0.240 ACC_seen: 0.230, ACC_unseen: 0.216\n",
      "[ Epoch: 29  TLoss: 6.988    Best_HMean:  0.240 ACC_seen: 0.225, ACC_unseen: 0.217\n",
      "[ Epoch: 30  TLoss: 6.996    Best_HMean:  0.240 ACC_seen: 0.229, ACC_unseen: 0.216\n",
      "[ Epoch: 31  TLoss: 6.990    Best_HMean:  0.240 ACC_seen: 0.236, ACC_unseen: 0.216\n",
      "[ Epoch: 32  TLoss: 6.996    Best_HMean:  0.240 ACC_seen: 0.236, ACC_unseen: 0.215\n",
      "[ Epoch: 33  TLoss: 6.973    Best_HMean:  0.240 ACC_seen: 0.237, ACC_unseen: 0.217\n",
      "[ Epoch: 34  TLoss: 6.990    Best_HMean:  0.240 ACC_seen: 0.236, ACC_unseen: 0.216\n",
      "[ Epoch: 35  TLoss: 6.983    Best_HMean:  0.240 ACC_seen: 0.236, ACC_unseen: 0.216\n",
      "[ Epoch: 36  TLoss: 6.983    Best_HMean:  0.240 ACC_seen: 0.236, ACC_unseen: 0.216\n",
      "[ Epoch: 37  TLoss: 6.988    Best_HMean:  0.240 ACC_seen: 0.236, ACC_unseen: 0.216\n",
      "[ Epoch: 38  TLoss: 7.006    Best_HMean:  0.240 ACC_seen: 0.238, ACC_unseen: 0.216\n",
      "[ Epoch: 39  TLoss: 6.986    Best_HMean:  0.240 ACC_seen: 0.240, ACC_unseen: 0.216\n",
      "[ Epoch: 40  TLoss: 6.998    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 41  TLoss: 6.962    Best_HMean:  0.240 ACC_seen: 0.244, ACC_unseen: 0.217\n",
      "[ Epoch: 42  TLoss: 6.968    Best_HMean:  0.240 ACC_seen: 0.245, ACC_unseen: 0.217\n",
      "[ Epoch: 43  TLoss: 6.974    Best_HMean:  0.240 ACC_seen: 0.244, ACC_unseen: 0.216\n",
      "[ Epoch: 44  TLoss: 6.975    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 45  TLoss: 6.971    Best_HMean:  0.240 ACC_seen: 0.244, ACC_unseen: 0.217\n",
      "[ Epoch: 46  TLoss: 6.963    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 47  TLoss: 6.991    Best_HMean:  0.240 ACC_seen: 0.242, ACC_unseen: 0.217\n",
      "[ Epoch: 48  TLoss: 6.965    Best_HMean:  0.240 ACC_seen: 0.238, ACC_unseen: 0.217\n",
      "[ Epoch: 49  TLoss: 6.979    Best_HMean:  0.240 ACC_seen: 0.239, ACC_unseen: 0.217\n",
      "[ Epoch: 50  TLoss: 6.984    Best_HMean:  0.240 ACC_seen: 0.239, ACC_unseen: 0.217\n",
      "[ Epoch: 51  TLoss: 6.968    Best_HMean:  0.240 ACC_seen: 0.241, ACC_unseen: 0.217\n",
      "[ Epoch: 52  TLoss: 6.984    Best_HMean:  0.240 ACC_seen: 0.241, ACC_unseen: 0.216\n",
      "[ Epoch: 53  TLoss: 6.974    Best_HMean:  0.240 ACC_seen: 0.239, ACC_unseen: 0.217\n",
      "[ Epoch: 54  TLoss: 6.974    Best_HMean:  0.240 ACC_seen: 0.239, ACC_unseen: 0.217\n",
      "[ Epoch: 55  TLoss: 6.957    Best_HMean:  0.240 ACC_seen: 0.239, ACC_unseen: 0.217\n",
      "[ Epoch: 56  TLoss: 6.990    Best_HMean:  0.240 ACC_seen: 0.237, ACC_unseen: 0.217\n",
      "[ Epoch: 57  TLoss: 6.972    Best_HMean:  0.240 ACC_seen: 0.237, ACC_unseen: 0.217\n",
      "[ Epoch: 58  TLoss: 6.971    Best_HMean:  0.240 ACC_seen: 0.237, ACC_unseen: 0.217\n",
      "[ Epoch: 59  TLoss: 6.980    Best_HMean:  0.240 ACC_seen: 0.237, ACC_unseen: 0.217\n",
      "[ Epoch: 60  TLoss: 6.973    Best_HMean:  0.240 ACC_seen: 0.242, ACC_unseen: 0.216\n",
      "[ Epoch: 61  TLoss: 6.962    Best_HMean:  0.240 ACC_seen: 0.242, ACC_unseen: 0.216\n",
      "[ Epoch: 62  TLoss: 6.969    Best_HMean:  0.240 ACC_seen: 0.242, ACC_unseen: 0.217\n",
      "[ Epoch: 63  TLoss: 6.945    Best_HMean:  0.240 ACC_seen: 0.244, ACC_unseen: 0.216\n",
      "[ Epoch: 64  TLoss: 6.963    Best_HMean:  0.240 ACC_seen: 0.244, ACC_unseen: 0.216\n",
      "[ Epoch: 65  TLoss: 6.965    Best_HMean:  0.240 ACC_seen: 0.244, ACC_unseen: 0.216\n",
      "[ Epoch: 66  TLoss: 6.969    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 67  TLoss: 6.970    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 68  TLoss: 6.963    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 69  TLoss: 6.969    Best_HMean:  0.240 ACC_seen: 0.244, ACC_unseen: 0.216\n",
      "[ Epoch: 70  TLoss: 6.981    Best_HMean:  0.240 ACC_seen: 0.244, ACC_unseen: 0.217\n",
      "[ Epoch: 71  TLoss: 6.976    Best_HMean:  0.240 ACC_seen: 0.245, ACC_unseen: 0.216\n",
      "[ Epoch: 72  TLoss: 6.994    Best_HMean:  0.240 ACC_seen: 0.244, ACC_unseen: 0.216\n",
      "[ Epoch: 73  TLoss: 6.984    Best_HMean:  0.240 ACC_seen: 0.242, ACC_unseen: 0.217\n",
      "[ Epoch: 74  TLoss: 6.967    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 75  TLoss: 6.964    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 76  TLoss: 6.968    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 77  TLoss: 6.956    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 78  TLoss: 6.962    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 79  TLoss: 7.007    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 80  TLoss: 6.957    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 81  TLoss: 6.961    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 82  TLoss: 6.969    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 83  TLoss: 6.961    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 84  TLoss: 6.955    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 85  TLoss: 6.979    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 86  TLoss: 6.974    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 87  TLoss: 6.969    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 88  TLoss: 6.963    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 89  TLoss: 6.958    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 90  TLoss: 6.981    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 91  TLoss: 6.981    Best_HMean:  0.240 ACC_seen: 0.242, ACC_unseen: 0.217\n",
      "[ Epoch: 92  TLoss: 6.960    Best_HMean:  0.240 ACC_seen: 0.242, ACC_unseen: 0.217\n",
      "[ Epoch: 93  TLoss: 6.972    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.217\n",
      "[ Epoch: 94  TLoss: 6.972    Best_HMean:  0.240 ACC_seen: 0.242, ACC_unseen: 0.217\n",
      "[ Epoch: 95  TLoss: 6.971    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 96  TLoss: 6.987    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 97  TLoss: 6.988    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 98  TLoss: 6.996    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[ Epoch: 99  TLoss: 6.983    Best_HMean:  0.240 ACC_seen: 0.243, ACC_unseen: 0.216\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233], [0.26659650816827546, 0.1833332416667125, 0.2172605926922656], [0.29156026543504593, 0.2041665645833844, 0.24015991936801118]]\n",
      "\n",
      "<=============== Training task 5===============>\n",
      "current_task_class[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284]\n",
      "task_testseen_class: (285,)\n",
      "task_testunseen_class: (432,)\n",
      "[ Epoch: 0  TLoss: 7.418    Best_HMean:  0.243 ACC_seen: 0.278, ACC_unseen: 0.216\n",
      "[ Epoch: 1  TLoss: 7.413    Best_HMean:  0.252 ACC_seen: 0.292, ACC_unseen: 0.222\n",
      "[ Epoch: 2  TLoss: 7.393    Best_HMean:  0.252 ACC_seen: 0.283, ACC_unseen: 0.221\n",
      "[ Epoch: 3  TLoss: 7.372    Best_HMean:  0.252 ACC_seen: 0.275, ACC_unseen: 0.220\n",
      "[ Epoch: 4  TLoss: 7.371    Best_HMean:  0.252 ACC_seen: 0.276, ACC_unseen: 0.220\n",
      "[ Epoch: 5  TLoss: 7.358    Best_HMean:  0.252 ACC_seen: 0.281, ACC_unseen: 0.221\n",
      "[ Epoch: 6  TLoss: 7.340    Best_HMean:  0.252 ACC_seen: 0.275, ACC_unseen: 0.223\n",
      "[ Epoch: 7  TLoss: 7.379    Best_HMean:  0.252 ACC_seen: 0.267, ACC_unseen: 0.226\n",
      "[ Epoch: 8  TLoss: 7.341    Best_HMean:  0.252 ACC_seen: 0.268, ACC_unseen: 0.225\n",
      "[ Epoch: 9  TLoss: 7.344    Best_HMean:  0.252 ACC_seen: 0.258, ACC_unseen: 0.228\n",
      "[ Epoch: 10  TLoss: 7.290    Best_HMean:  0.252 ACC_seen: 0.262, ACC_unseen: 0.229\n",
      "[ Epoch: 11  TLoss: 7.301    Best_HMean:  0.252 ACC_seen: 0.269, ACC_unseen: 0.230\n",
      "[ Epoch: 12  TLoss: 7.330    Best_HMean:  0.252 ACC_seen: 0.262, ACC_unseen: 0.231\n",
      "[ Epoch: 13  TLoss: 7.295    Best_HMean:  0.252 ACC_seen: 0.247, ACC_unseen: 0.231\n",
      "[ Epoch: 14  TLoss: 7.294    Best_HMean:  0.252 ACC_seen: 0.244, ACC_unseen: 0.228\n",
      "[ Epoch: 15  TLoss: 7.280    Best_HMean:  0.252 ACC_seen: 0.248, ACC_unseen: 0.226\n",
      "[ Epoch: 16  TLoss: 7.327    Best_HMean:  0.252 ACC_seen: 0.257, ACC_unseen: 0.228\n",
      "[ Epoch: 17  TLoss: 7.298    Best_HMean:  0.252 ACC_seen: 0.265, ACC_unseen: 0.232\n",
      "[ Epoch: 18  TLoss: 7.306    Best_HMean:  0.252 ACC_seen: 0.259, ACC_unseen: 0.229\n",
      "[ Epoch: 19  TLoss: 7.308    Best_HMean:  0.252 ACC_seen: 0.255, ACC_unseen: 0.229\n",
      "[ Epoch: 20  TLoss: 7.277    Best_HMean:  0.252 ACC_seen: 0.252, ACC_unseen: 0.232\n",
      "[ Epoch: 21  TLoss: 7.289    Best_HMean:  0.252 ACC_seen: 0.257, ACC_unseen: 0.236\n",
      "[ Epoch: 22  TLoss: 7.294    Best_HMean:  0.252 ACC_seen: 0.249, ACC_unseen: 0.233\n",
      "[ Epoch: 23  TLoss: 7.303    Best_HMean:  0.252 ACC_seen: 0.254, ACC_unseen: 0.232\n",
      "[ Epoch: 24  TLoss: 7.279    Best_HMean:  0.252 ACC_seen: 0.243, ACC_unseen: 0.233\n",
      "[ Epoch: 25  TLoss: 7.263    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.233\n",
      "[ Epoch: 26  TLoss: 7.261    Best_HMean:  0.252 ACC_seen: 0.236, ACC_unseen: 0.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 27  TLoss: 7.248    Best_HMean:  0.252 ACC_seen: 0.245, ACC_unseen: 0.234\n",
      "[ Epoch: 28  TLoss: 7.213    Best_HMean:  0.252 ACC_seen: 0.244, ACC_unseen: 0.234\n",
      "[ Epoch: 29  TLoss: 7.253    Best_HMean:  0.252 ACC_seen: 0.246, ACC_unseen: 0.234\n",
      "[ Epoch: 30  TLoss: 7.278    Best_HMean:  0.252 ACC_seen: 0.248, ACC_unseen: 0.233\n",
      "[ Epoch: 31  TLoss: 7.242    Best_HMean:  0.252 ACC_seen: 0.246, ACC_unseen: 0.233\n",
      "[ Epoch: 32  TLoss: 7.259    Best_HMean:  0.252 ACC_seen: 0.245, ACC_unseen: 0.234\n",
      "[ Epoch: 33  TLoss: 7.258    Best_HMean:  0.252 ACC_seen: 0.244, ACC_unseen: 0.236\n",
      "[ Epoch: 34  TLoss: 7.254    Best_HMean:  0.252 ACC_seen: 0.247, ACC_unseen: 0.235\n",
      "[ Epoch: 35  TLoss: 7.268    Best_HMean:  0.252 ACC_seen: 0.244, ACC_unseen: 0.235\n",
      "[ Epoch: 36  TLoss: 7.245    Best_HMean:  0.252 ACC_seen: 0.244, ACC_unseen: 0.236\n",
      "[ Epoch: 37  TLoss: 7.256    Best_HMean:  0.252 ACC_seen: 0.246, ACC_unseen: 0.236\n",
      "[ Epoch: 38  TLoss: 7.234    Best_HMean:  0.252 ACC_seen: 0.244, ACC_unseen: 0.234\n",
      "[ Epoch: 39  TLoss: 7.235    Best_HMean:  0.252 ACC_seen: 0.244, ACC_unseen: 0.234\n",
      "[ Epoch: 40  TLoss: 7.273    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.233\n",
      "[ Epoch: 41  TLoss: 7.242    Best_HMean:  0.252 ACC_seen: 0.238, ACC_unseen: 0.234\n",
      "[ Epoch: 42  TLoss: 7.249    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.233\n",
      "[ Epoch: 43  TLoss: 7.267    Best_HMean:  0.252 ACC_seen: 0.243, ACC_unseen: 0.233\n",
      "[ Epoch: 44  TLoss: 7.228    Best_HMean:  0.252 ACC_seen: 0.244, ACC_unseen: 0.233\n",
      "[ Epoch: 45  TLoss: 7.233    Best_HMean:  0.252 ACC_seen: 0.244, ACC_unseen: 0.233\n",
      "[ Epoch: 46  TLoss: 7.242    Best_HMean:  0.252 ACC_seen: 0.244, ACC_unseen: 0.233\n",
      "[ Epoch: 47  TLoss: 7.230    Best_HMean:  0.252 ACC_seen: 0.247, ACC_unseen: 0.234\n",
      "[ Epoch: 48  TLoss: 7.232    Best_HMean:  0.252 ACC_seen: 0.243, ACC_unseen: 0.234\n",
      "[ Epoch: 49  TLoss: 7.284    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.233\n",
      "[ Epoch: 50  TLoss: 7.237    Best_HMean:  0.252 ACC_seen: 0.242, ACC_unseen: 0.234\n",
      "[ Epoch: 51  TLoss: 7.242    Best_HMean:  0.252 ACC_seen: 0.242, ACC_unseen: 0.234\n",
      "[ Epoch: 52  TLoss: 7.255    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 53  TLoss: 7.231    Best_HMean:  0.252 ACC_seen: 0.239, ACC_unseen: 0.234\n",
      "[ Epoch: 54  TLoss: 7.253    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.234\n",
      "[ Epoch: 55  TLoss: 7.242    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.234\n",
      "[ Epoch: 56  TLoss: 7.253    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.234\n",
      "[ Epoch: 57  TLoss: 7.221    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.234\n",
      "[ Epoch: 58  TLoss: 7.243    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.233\n",
      "[ Epoch: 59  TLoss: 7.234    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.233\n",
      "[ Epoch: 60  TLoss: 7.209    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.233\n",
      "[ Epoch: 61  TLoss: 7.249    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 62  TLoss: 7.276    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.233\n",
      "[ Epoch: 63  TLoss: 7.253    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.233\n",
      "[ Epoch: 64  TLoss: 7.208    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 65  TLoss: 7.267    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 66  TLoss: 7.221    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 67  TLoss: 7.237    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.234\n",
      "[ Epoch: 68  TLoss: 7.239    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.234\n",
      "[ Epoch: 69  TLoss: 7.252    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.234\n",
      "[ Epoch: 70  TLoss: 7.241    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 71  TLoss: 7.219    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 72  TLoss: 7.245    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 73  TLoss: 7.239    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 74  TLoss: 7.252    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 75  TLoss: 7.240    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 76  TLoss: 7.237    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 77  TLoss: 7.239    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.234\n",
      "[ Epoch: 78  TLoss: 7.255    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.234\n",
      "[ Epoch: 79  TLoss: 7.253    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 80  TLoss: 7.210    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 81  TLoss: 7.229    Best_HMean:  0.252 ACC_seen: 0.239, ACC_unseen: 0.234\n",
      "[ Epoch: 82  TLoss: 7.248    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 83  TLoss: 7.228    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 84  TLoss: 7.242    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 85  TLoss: 7.245    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 86  TLoss: 7.250    Best_HMean:  0.252 ACC_seen: 0.241, ACC_unseen: 0.234\n",
      "[ Epoch: 87  TLoss: 7.205    Best_HMean:  0.252 ACC_seen: 0.239, ACC_unseen: 0.234\n",
      "[ Epoch: 88  TLoss: 7.229    Best_HMean:  0.252 ACC_seen: 0.239, ACC_unseen: 0.234\n",
      "[ Epoch: 89  TLoss: 7.225    Best_HMean:  0.252 ACC_seen: 0.239, ACC_unseen: 0.234\n",
      "[ Epoch: 90  TLoss: 7.244    Best_HMean:  0.252 ACC_seen: 0.239, ACC_unseen: 0.234\n",
      "[ Epoch: 91  TLoss: 7.284    Best_HMean:  0.252 ACC_seen: 0.239, ACC_unseen: 0.234\n",
      "[ Epoch: 92  TLoss: 7.232    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 93  TLoss: 7.238    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 94  TLoss: 7.219    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 95  TLoss: 7.245    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.235\n",
      "[ Epoch: 96  TLoss: 7.222    Best_HMean:  0.252 ACC_seen: 0.240, ACC_unseen: 0.234\n",
      "[ Epoch: 97  TLoss: 7.235    Best_HMean:  0.252 ACC_seen: 0.239, ACC_unseen: 0.235\n",
      "[ Epoch: 98  TLoss: 7.257    Best_HMean:  0.252 ACC_seen: 0.239, ACC_unseen: 0.234\n",
      "[ Epoch: 99  TLoss: 7.220    Best_HMean:  0.252 ACC_seen: 0.239, ACC_unseen: 0.234\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233], [0.26659650816827546, 0.1833332416667125, 0.2172605926922656], [0.29156026543504593, 0.2041665645833844, 0.24015991936801118], [0.29192475565473125, 0.22175914837968508, 0.2520498878649059]]\n",
      "\n",
      "<=============== Training task 6===============>\n",
      "current_task_class[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332]\n",
      "task_testseen_class: (333,)\n",
      "task_testunseen_class: (384,)\n",
      "[ Epoch: 0  TLoss: 7.884    Best_HMean:  0.262 ACC_seen: 0.290, ACC_unseen: 0.238\n",
      "[ Epoch: 1  TLoss: 7.718    Best_HMean:  0.263 ACC_seen: 0.296, ACC_unseen: 0.236\n",
      "[ Epoch: 2  TLoss: 7.655    Best_HMean:  0.269 ACC_seen: 0.315, ACC_unseen: 0.235\n",
      "[ Epoch: 3  TLoss: 7.627    Best_HMean:  0.269 ACC_seen: 0.305, ACC_unseen: 0.239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 4  TLoss: 7.626    Best_HMean:  0.269 ACC_seen: 0.291, ACC_unseen: 0.236\n",
      "[ Epoch: 5  TLoss: 7.566    Best_HMean:  0.269 ACC_seen: 0.290, ACC_unseen: 0.242\n",
      "[ Epoch: 6  TLoss: 7.561    Best_HMean:  0.269 ACC_seen: 0.289, ACC_unseen: 0.246\n",
      "[ Epoch: 7  TLoss: 7.554    Best_HMean:  0.269 ACC_seen: 0.289, ACC_unseen: 0.247\n",
      "[ Epoch: 8  TLoss: 7.533    Best_HMean:  0.269 ACC_seen: 0.281, ACC_unseen: 0.245\n",
      "[ Epoch: 9  TLoss: 7.508    Best_HMean:  0.269 ACC_seen: 0.282, ACC_unseen: 0.247\n",
      "[ Epoch: 10  TLoss: 7.521    Best_HMean:  0.269 ACC_seen: 0.284, ACC_unseen: 0.249\n",
      "[ Epoch: 11  TLoss: 7.507    Best_HMean:  0.269 ACC_seen: 0.282, ACC_unseen: 0.250\n",
      "[ Epoch: 12  TLoss: 7.536    Best_HMean:  0.269 ACC_seen: 0.278, ACC_unseen: 0.251\n",
      "[ Epoch: 13  TLoss: 7.508    Best_HMean:  0.269 ACC_seen: 0.278, ACC_unseen: 0.248\n",
      "[ Epoch: 14  TLoss: 7.498    Best_HMean:  0.269 ACC_seen: 0.268, ACC_unseen: 0.249\n",
      "[ Epoch: 15  TLoss: 7.495    Best_HMean:  0.269 ACC_seen: 0.266, ACC_unseen: 0.250\n",
      "[ Epoch: 16  TLoss: 7.465    Best_HMean:  0.269 ACC_seen: 0.265, ACC_unseen: 0.251\n",
      "[ Epoch: 17  TLoss: 7.474    Best_HMean:  0.269 ACC_seen: 0.261, ACC_unseen: 0.253\n",
      "[ Epoch: 18  TLoss: 7.480    Best_HMean:  0.269 ACC_seen: 0.263, ACC_unseen: 0.250\n",
      "[ Epoch: 19  TLoss: 7.466    Best_HMean:  0.269 ACC_seen: 0.265, ACC_unseen: 0.251\n",
      "[ Epoch: 20  TLoss: 7.484    Best_HMean:  0.269 ACC_seen: 0.264, ACC_unseen: 0.251\n",
      "[ Epoch: 21  TLoss: 7.460    Best_HMean:  0.269 ACC_seen: 0.268, ACC_unseen: 0.257\n",
      "[ Epoch: 22  TLoss: 7.462    Best_HMean:  0.269 ACC_seen: 0.258, ACC_unseen: 0.254\n",
      "[ Epoch: 23  TLoss: 7.462    Best_HMean:  0.269 ACC_seen: 0.264, ACC_unseen: 0.249\n",
      "[ Epoch: 24  TLoss: 7.478    Best_HMean:  0.269 ACC_seen: 0.261, ACC_unseen: 0.250\n",
      "[ Epoch: 25  TLoss: 7.428    Best_HMean:  0.269 ACC_seen: 0.260, ACC_unseen: 0.250\n",
      "[ Epoch: 26  TLoss: 7.469    Best_HMean:  0.269 ACC_seen: 0.260, ACC_unseen: 0.251\n",
      "[ Epoch: 27  TLoss: 7.452    Best_HMean:  0.269 ACC_seen: 0.261, ACC_unseen: 0.252\n",
      "[ Epoch: 28  TLoss: 7.435    Best_HMean:  0.269 ACC_seen: 0.261, ACC_unseen: 0.252\n",
      "[ Epoch: 29  TLoss: 7.436    Best_HMean:  0.269 ACC_seen: 0.263, ACC_unseen: 0.255\n",
      "[ Epoch: 30  TLoss: 7.437    Best_HMean:  0.269 ACC_seen: 0.260, ACC_unseen: 0.255\n",
      "[ Epoch: 31  TLoss: 7.421    Best_HMean:  0.269 ACC_seen: 0.259, ACC_unseen: 0.256\n",
      "[ Epoch: 32  TLoss: 7.440    Best_HMean:  0.269 ACC_seen: 0.260, ACC_unseen: 0.257\n",
      "[ Epoch: 33  TLoss: 7.420    Best_HMean:  0.269 ACC_seen: 0.261, ACC_unseen: 0.258\n",
      "[ Epoch: 34  TLoss: 7.426    Best_HMean:  0.269 ACC_seen: 0.267, ACC_unseen: 0.257\n",
      "[ Epoch: 35  TLoss: 7.427    Best_HMean:  0.269 ACC_seen: 0.265, ACC_unseen: 0.257\n",
      "[ Epoch: 36  TLoss: 7.435    Best_HMean:  0.269 ACC_seen: 0.261, ACC_unseen: 0.257\n",
      "[ Epoch: 37  TLoss: 7.428    Best_HMean:  0.269 ACC_seen: 0.256, ACC_unseen: 0.257\n",
      "[ Epoch: 38  TLoss: 7.418    Best_HMean:  0.269 ACC_seen: 0.254, ACC_unseen: 0.256\n",
      "[ Epoch: 39  TLoss: 7.419    Best_HMean:  0.269 ACC_seen: 0.255, ACC_unseen: 0.256\n",
      "[ Epoch: 40  TLoss: 7.425    Best_HMean:  0.269 ACC_seen: 0.255, ACC_unseen: 0.255\n",
      "[ Epoch: 41  TLoss: 7.427    Best_HMean:  0.269 ACC_seen: 0.255, ACC_unseen: 0.255\n",
      "[ Epoch: 42  TLoss: 7.425    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.257\n",
      "[ Epoch: 43  TLoss: 7.420    Best_HMean:  0.269 ACC_seen: 0.258, ACC_unseen: 0.256\n",
      "[ Epoch: 44  TLoss: 7.412    Best_HMean:  0.269 ACC_seen: 0.254, ACC_unseen: 0.256\n",
      "[ Epoch: 45  TLoss: 7.423    Best_HMean:  0.269 ACC_seen: 0.252, ACC_unseen: 0.256\n",
      "[ Epoch: 46  TLoss: 7.422    Best_HMean:  0.269 ACC_seen: 0.255, ACC_unseen: 0.255\n",
      "[ Epoch: 47  TLoss: 7.412    Best_HMean:  0.269 ACC_seen: 0.252, ACC_unseen: 0.256\n",
      "[ Epoch: 48  TLoss: 7.412    Best_HMean:  0.269 ACC_seen: 0.253, ACC_unseen: 0.257\n",
      "[ Epoch: 49  TLoss: 7.416    Best_HMean:  0.269 ACC_seen: 0.255, ACC_unseen: 0.256\n",
      "[ Epoch: 50  TLoss: 7.407    Best_HMean:  0.269 ACC_seen: 0.254, ACC_unseen: 0.256\n",
      "[ Epoch: 51  TLoss: 7.409    Best_HMean:  0.269 ACC_seen: 0.254, ACC_unseen: 0.256\n",
      "[ Epoch: 52  TLoss: 7.416    Best_HMean:  0.269 ACC_seen: 0.255, ACC_unseen: 0.256\n",
      "[ Epoch: 53  TLoss: 7.414    Best_HMean:  0.269 ACC_seen: 0.255, ACC_unseen: 0.255\n",
      "[ Epoch: 54  TLoss: 7.382    Best_HMean:  0.269 ACC_seen: 0.255, ACC_unseen: 0.256\n",
      "[ Epoch: 55  TLoss: 7.404    Best_HMean:  0.269 ACC_seen: 0.255, ACC_unseen: 0.256\n",
      "[ Epoch: 56  TLoss: 7.402    Best_HMean:  0.269 ACC_seen: 0.255, ACC_unseen: 0.256\n",
      "[ Epoch: 57  TLoss: 7.409    Best_HMean:  0.269 ACC_seen: 0.254, ACC_unseen: 0.256\n",
      "[ Epoch: 58  TLoss: 7.399    Best_HMean:  0.269 ACC_seen: 0.254, ACC_unseen: 0.256\n",
      "[ Epoch: 59  TLoss: 7.391    Best_HMean:  0.269 ACC_seen: 0.254, ACC_unseen: 0.256\n",
      "[ Epoch: 60  TLoss: 7.396    Best_HMean:  0.269 ACC_seen: 0.256, ACC_unseen: 0.255\n",
      "[ Epoch: 61  TLoss: 7.410    Best_HMean:  0.269 ACC_seen: 0.256, ACC_unseen: 0.255\n",
      "[ Epoch: 62  TLoss: 7.396    Best_HMean:  0.269 ACC_seen: 0.256, ACC_unseen: 0.255\n",
      "[ Epoch: 63  TLoss: 7.395    Best_HMean:  0.269 ACC_seen: 0.256, ACC_unseen: 0.255\n",
      "[ Epoch: 64  TLoss: 7.412    Best_HMean:  0.269 ACC_seen: 0.253, ACC_unseen: 0.255\n",
      "[ Epoch: 65  TLoss: 7.406    Best_HMean:  0.269 ACC_seen: 0.253, ACC_unseen: 0.255\n",
      "[ Epoch: 66  TLoss: 7.410    Best_HMean:  0.269 ACC_seen: 0.253, ACC_unseen: 0.255\n",
      "[ Epoch: 67  TLoss: 7.406    Best_HMean:  0.269 ACC_seen: 0.253, ACC_unseen: 0.255\n",
      "[ Epoch: 68  TLoss: 7.400    Best_HMean:  0.269 ACC_seen: 0.253, ACC_unseen: 0.255\n",
      "[ Epoch: 69  TLoss: 7.411    Best_HMean:  0.269 ACC_seen: 0.253, ACC_unseen: 0.255\n",
      "[ Epoch: 70  TLoss: 7.435    Best_HMean:  0.269 ACC_seen: 0.253, ACC_unseen: 0.255\n",
      "[ Epoch: 71  TLoss: 7.417    Best_HMean:  0.269 ACC_seen: 0.253, ACC_unseen: 0.255\n",
      "[ Epoch: 72  TLoss: 7.405    Best_HMean:  0.269 ACC_seen: 0.254, ACC_unseen: 0.255\n",
      "[ Epoch: 73  TLoss: 7.390    Best_HMean:  0.269 ACC_seen: 0.256, ACC_unseen: 0.255\n",
      "[ Epoch: 74  TLoss: 7.417    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 75  TLoss: 7.400    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 76  TLoss: 7.432    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 77  TLoss: 7.414    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 78  TLoss: 7.417    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 79  TLoss: 7.439    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 80  TLoss: 7.410    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 81  TLoss: 7.400    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 82  TLoss: 7.421    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 83  TLoss: 7.411    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.256\n",
      "[ Epoch: 84  TLoss: 7.422    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 85  TLoss: 7.399    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 86  TLoss: 7.409    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 87  TLoss: 7.399    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 88  TLoss: 7.412    Best_HMean:  0.269 ACC_seen: 0.254, ACC_unseen: 0.255\n",
      "[ Epoch: 89  TLoss: 7.424    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 90  TLoss: 7.395    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 91  TLoss: 7.414    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 92  TLoss: 7.404    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.256\n",
      "[ Epoch: 93  TLoss: 7.419    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 94  TLoss: 7.400    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 95  TLoss: 7.413    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 96  TLoss: 7.407    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 97  TLoss: 7.406    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 98  TLoss: 7.412    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[ Epoch: 99  TLoss: 7.404    Best_HMean:  0.269 ACC_seen: 0.257, ACC_unseen: 0.255\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233], [0.26659650816827546, 0.1833332416667125, 0.2172605926922656], [0.29156026543504593, 0.2041665645833844, 0.24015991936801118], [0.29192475565473125, 0.22175914837968508, 0.2520498878649059], [0.3149413446758019, 0.23463529934901697, 0.2689210230777258]]\n",
      "\n",
      "<=============== Training task 7===============>\n",
      "current_task_class[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380]\n",
      "task_testseen_class: (381,)\n",
      "task_testunseen_class: (336,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 0  TLoss: 7.825    Best_HMean:  0.279 ACC_seen: 0.308, ACC_unseen: 0.256\n",
      "[ Epoch: 1  TLoss: 7.772    Best_HMean:  0.284 ACC_seen: 0.310, ACC_unseen: 0.261\n",
      "[ Epoch: 2  TLoss: 7.743    Best_HMean:  0.291 ACC_seen: 0.327, ACC_unseen: 0.263\n",
      "[ Epoch: 3  TLoss: 7.704    Best_HMean:  0.291 ACC_seen: 0.318, ACC_unseen: 0.261\n",
      "[ Epoch: 4  TLoss: 7.705    Best_HMean:  0.291 ACC_seen: 0.312, ACC_unseen: 0.255\n",
      "[ Epoch: 5  TLoss: 7.717    Best_HMean:  0.291 ACC_seen: 0.303, ACC_unseen: 0.261\n",
      "[ Epoch: 6  TLoss: 7.680    Best_HMean:  0.291 ACC_seen: 0.300, ACC_unseen: 0.259\n",
      "[ Epoch: 7  TLoss: 7.649    Best_HMean:  0.291 ACC_seen: 0.298, ACC_unseen: 0.258\n",
      "[ Epoch: 8  TLoss: 7.632    Best_HMean:  0.291 ACC_seen: 0.300, ACC_unseen: 0.259\n",
      "[ Epoch: 9  TLoss: 7.658    Best_HMean:  0.291 ACC_seen: 0.298, ACC_unseen: 0.261\n",
      "[ Epoch: 10  TLoss: 7.638    Best_HMean:  0.291 ACC_seen: 0.299, ACC_unseen: 0.260\n",
      "[ Epoch: 11  TLoss: 7.673    Best_HMean:  0.291 ACC_seen: 0.297, ACC_unseen: 0.263\n",
      "[ Epoch: 12  TLoss: 7.632    Best_HMean:  0.291 ACC_seen: 0.294, ACC_unseen: 0.263\n",
      "[ Epoch: 13  TLoss: 7.626    Best_HMean:  0.291 ACC_seen: 0.299, ACC_unseen: 0.265\n",
      "[ Epoch: 14  TLoss: 7.634    Best_HMean:  0.291 ACC_seen: 0.290, ACC_unseen: 0.264\n",
      "[ Epoch: 15  TLoss: 7.632    Best_HMean:  0.291 ACC_seen: 0.280, ACC_unseen: 0.270\n",
      "[ Epoch: 16  TLoss: 7.598    Best_HMean:  0.291 ACC_seen: 0.268, ACC_unseen: 0.268\n",
      "[ Epoch: 17  TLoss: 7.603    Best_HMean:  0.291 ACC_seen: 0.270, ACC_unseen: 0.265\n",
      "[ Epoch: 18  TLoss: 7.649    Best_HMean:  0.291 ACC_seen: 0.281, ACC_unseen: 0.266\n",
      "[ Epoch: 19  TLoss: 7.634    Best_HMean:  0.291 ACC_seen: 0.269, ACC_unseen: 0.265\n",
      "[ Epoch: 20  TLoss: 7.619    Best_HMean:  0.291 ACC_seen: 0.276, ACC_unseen: 0.266\n",
      "[ Epoch: 21  TLoss: 7.624    Best_HMean:  0.291 ACC_seen: 0.268, ACC_unseen: 0.267\n",
      "[ Epoch: 22  TLoss: 7.607    Best_HMean:  0.291 ACC_seen: 0.267, ACC_unseen: 0.268\n",
      "[ Epoch: 23  TLoss: 7.614    Best_HMean:  0.291 ACC_seen: 0.268, ACC_unseen: 0.270\n",
      "[ Epoch: 24  TLoss: 7.572    Best_HMean:  0.291 ACC_seen: 0.258, ACC_unseen: 0.273\n",
      "[ Epoch: 25  TLoss: 7.618    Best_HMean:  0.291 ACC_seen: 0.259, ACC_unseen: 0.273\n",
      "[ Epoch: 26  TLoss: 7.604    Best_HMean:  0.291 ACC_seen: 0.260, ACC_unseen: 0.274\n",
      "[ Epoch: 27  TLoss: 7.561    Best_HMean:  0.291 ACC_seen: 0.267, ACC_unseen: 0.275\n",
      "[ Epoch: 28  TLoss: 7.588    Best_HMean:  0.291 ACC_seen: 0.267, ACC_unseen: 0.276\n",
      "[ Epoch: 29  TLoss: 7.580    Best_HMean:  0.291 ACC_seen: 0.269, ACC_unseen: 0.277\n",
      "[ Epoch: 30  TLoss: 7.578    Best_HMean:  0.291 ACC_seen: 0.268, ACC_unseen: 0.277\n",
      "[ Epoch: 31  TLoss: 7.574    Best_HMean:  0.291 ACC_seen: 0.271, ACC_unseen: 0.276\n",
      "[ Epoch: 32  TLoss: 7.574    Best_HMean:  0.291 ACC_seen: 0.269, ACC_unseen: 0.277\n",
      "[ Epoch: 33  TLoss: 7.567    Best_HMean:  0.291 ACC_seen: 0.267, ACC_unseen: 0.278\n",
      "[ Epoch: 34  TLoss: 7.574    Best_HMean:  0.291 ACC_seen: 0.266, ACC_unseen: 0.276\n",
      "[ Epoch: 35  TLoss: 7.578    Best_HMean:  0.291 ACC_seen: 0.270, ACC_unseen: 0.276\n",
      "[ Epoch: 36  TLoss: 7.571    Best_HMean:  0.291 ACC_seen: 0.268, ACC_unseen: 0.276\n",
      "[ Epoch: 37  TLoss: 7.549    Best_HMean:  0.291 ACC_seen: 0.270, ACC_unseen: 0.275\n",
      "[ Epoch: 38  TLoss: 7.547    Best_HMean:  0.291 ACC_seen: 0.267, ACC_unseen: 0.276\n",
      "[ Epoch: 39  TLoss: 7.559    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.278\n",
      "[ Epoch: 40  TLoss: 7.554    Best_HMean:  0.291 ACC_seen: 0.262, ACC_unseen: 0.278\n",
      "[ Epoch: 41  TLoss: 7.539    Best_HMean:  0.291 ACC_seen: 0.260, ACC_unseen: 0.278\n",
      "[ Epoch: 42  TLoss: 7.579    Best_HMean:  0.291 ACC_seen: 0.259, ACC_unseen: 0.276\n",
      "[ Epoch: 43  TLoss: 7.544    Best_HMean:  0.291 ACC_seen: 0.260, ACC_unseen: 0.275\n",
      "[ Epoch: 44  TLoss: 7.547    Best_HMean:  0.291 ACC_seen: 0.264, ACC_unseen: 0.274\n",
      "[ Epoch: 45  TLoss: 7.550    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 46  TLoss: 7.552    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 47  TLoss: 7.538    Best_HMean:  0.291 ACC_seen: 0.266, ACC_unseen: 0.273\n",
      "[ Epoch: 48  TLoss: 7.570    Best_HMean:  0.291 ACC_seen: 0.266, ACC_unseen: 0.274\n",
      "[ Epoch: 49  TLoss: 7.537    Best_HMean:  0.291 ACC_seen: 0.264, ACC_unseen: 0.274\n",
      "[ Epoch: 50  TLoss: 7.560    Best_HMean:  0.291 ACC_seen: 0.264, ACC_unseen: 0.274\n",
      "[ Epoch: 51  TLoss: 7.563    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 52  TLoss: 7.557    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 53  TLoss: 7.548    Best_HMean:  0.291 ACC_seen: 0.264, ACC_unseen: 0.275\n",
      "[ Epoch: 54  TLoss: 7.554    Best_HMean:  0.291 ACC_seen: 0.264, ACC_unseen: 0.275\n",
      "[ Epoch: 55  TLoss: 7.578    Best_HMean:  0.291 ACC_seen: 0.264, ACC_unseen: 0.275\n",
      "[ Epoch: 56  TLoss: 7.548    Best_HMean:  0.291 ACC_seen: 0.263, ACC_unseen: 0.275\n",
      "[ Epoch: 57  TLoss: 7.545    Best_HMean:  0.291 ACC_seen: 0.263, ACC_unseen: 0.276\n",
      "[ Epoch: 58  TLoss: 7.538    Best_HMean:  0.291 ACC_seen: 0.263, ACC_unseen: 0.275\n",
      "[ Epoch: 59  TLoss: 7.526    Best_HMean:  0.291 ACC_seen: 0.263, ACC_unseen: 0.275\n",
      "[ Epoch: 60  TLoss: 7.540    Best_HMean:  0.291 ACC_seen: 0.263, ACC_unseen: 0.274\n",
      "[ Epoch: 61  TLoss: 7.549    Best_HMean:  0.291 ACC_seen: 0.263, ACC_unseen: 0.274\n",
      "[ Epoch: 62  TLoss: 7.542    Best_HMean:  0.291 ACC_seen: 0.264, ACC_unseen: 0.274\n",
      "[ Epoch: 63  TLoss: 7.569    Best_HMean:  0.291 ACC_seen: 0.264, ACC_unseen: 0.274\n",
      "[ Epoch: 64  TLoss: 7.544    Best_HMean:  0.291 ACC_seen: 0.264, ACC_unseen: 0.274\n",
      "[ Epoch: 65  TLoss: 7.551    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 66  TLoss: 7.541    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 67  TLoss: 7.569    Best_HMean:  0.291 ACC_seen: 0.266, ACC_unseen: 0.274\n",
      "[ Epoch: 68  TLoss: 7.553    Best_HMean:  0.291 ACC_seen: 0.266, ACC_unseen: 0.274\n",
      "[ Epoch: 69  TLoss: 7.552    Best_HMean:  0.291 ACC_seen: 0.266, ACC_unseen: 0.274\n",
      "[ Epoch: 70  TLoss: 7.543    Best_HMean:  0.291 ACC_seen: 0.267, ACC_unseen: 0.274\n",
      "[ Epoch: 71  TLoss: 7.547    Best_HMean:  0.291 ACC_seen: 0.267, ACC_unseen: 0.274\n",
      "[ Epoch: 72  TLoss: 7.561    Best_HMean:  0.291 ACC_seen: 0.267, ACC_unseen: 0.274\n",
      "[ Epoch: 73  TLoss: 7.545    Best_HMean:  0.291 ACC_seen: 0.266, ACC_unseen: 0.274\n",
      "[ Epoch: 74  TLoss: 7.542    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.275\n",
      "[ Epoch: 75  TLoss: 7.566    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 76  TLoss: 7.539    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 77  TLoss: 7.545    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 78  TLoss: 7.553    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 79  TLoss: 7.550    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 80  TLoss: 7.546    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 81  TLoss: 7.558    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 82  TLoss: 7.561    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 83  TLoss: 7.537    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 84  TLoss: 7.545    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 85  TLoss: 7.537    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 86  TLoss: 7.525    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 87  TLoss: 7.556    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 88  TLoss: 7.556    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 89  TLoss: 7.541    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 90  TLoss: 7.561    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 91  TLoss: 7.549    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 92  TLoss: 7.542    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 93  TLoss: 7.542    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 94  TLoss: 7.539    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 95  TLoss: 7.555    Best_HMean:  0.291 ACC_seen: 0.265, ACC_unseen: 0.274\n",
      "[ Epoch: 96  TLoss: 7.549    Best_HMean:  0.291 ACC_seen: 0.267, ACC_unseen: 0.274\n",
      "[ Epoch: 97  TLoss: 7.548    Best_HMean:  0.291 ACC_seen: 0.267, ACC_unseen: 0.274\n",
      "[ Epoch: 98  TLoss: 7.556    Best_HMean:  0.291 ACC_seen: 0.267, ACC_unseen: 0.274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 99  TLoss: 7.553    Best_HMean:  0.291 ACC_seen: 0.267, ACC_unseen: 0.274\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233], [0.26659650816827546, 0.1833332416667125, 0.2172605926922656], [0.29156026543504593, 0.2041665645833844, 0.24015991936801118], [0.29192475565473125, 0.22175914837968508, 0.2520498878649059], [0.3149413446758019, 0.23463529934901697, 0.2689210230777258], [0.32659144220220343, 0.2630951065476848, 0.2914246915277531]]\n",
      "\n",
      "<=============== Training task 8===============>\n",
      "current_task_class[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428]\n",
      "task_testseen_class: (429,)\n",
      "task_testunseen_class: (288,)\n",
      "[ Epoch: 0  TLoss: 8.139    Best_HMean:  0.279 ACC_seen: 0.287, ACC_unseen: 0.272\n",
      "[ Epoch: 1  TLoss: 8.026    Best_HMean:  0.283 ACC_seen: 0.298, ACC_unseen: 0.270\n",
      "[ Epoch: 2  TLoss: 8.000    Best_HMean:  0.284 ACC_seen: 0.306, ACC_unseen: 0.265\n",
      "[ Epoch: 3  TLoss: 7.922    Best_HMean:  0.284 ACC_seen: 0.303, ACC_unseen: 0.260\n",
      "[ Epoch: 4  TLoss: 7.891    Best_HMean:  0.284 ACC_seen: 0.300, ACC_unseen: 0.264\n",
      "[ Epoch: 5  TLoss: 7.888    Best_HMean:  0.287 ACC_seen: 0.305, ACC_unseen: 0.272\n",
      "[ Epoch: 6  TLoss: 7.870    Best_HMean:  0.287 ACC_seen: 0.297, ACC_unseen: 0.268\n",
      "[ Epoch: 7  TLoss: 7.869    Best_HMean:  0.287 ACC_seen: 0.302, ACC_unseen: 0.270\n",
      "[ Epoch: 8  TLoss: 7.843    Best_HMean:  0.287 ACC_seen: 0.292, ACC_unseen: 0.275\n",
      "[ Epoch: 9  TLoss: 7.835    Best_HMean:  0.287 ACC_seen: 0.291, ACC_unseen: 0.271\n",
      "[ Epoch: 10  TLoss: 7.834    Best_HMean:  0.287 ACC_seen: 0.283, ACC_unseen: 0.265\n",
      "[ Epoch: 11  TLoss: 7.795    Best_HMean:  0.287 ACC_seen: 0.288, ACC_unseen: 0.269\n",
      "[ Epoch: 12  TLoss: 7.790    Best_HMean:  0.287 ACC_seen: 0.283, ACC_unseen: 0.276\n",
      "[ Epoch: 13  TLoss: 7.796    Best_HMean:  0.287 ACC_seen: 0.286, ACC_unseen: 0.281\n",
      "[ Epoch: 14  TLoss: 7.798    Best_HMean:  0.287 ACC_seen: 0.280, ACC_unseen: 0.279\n",
      "[ Epoch: 15  TLoss: 7.794    Best_HMean:  0.287 ACC_seen: 0.283, ACC_unseen: 0.278\n",
      "[ Epoch: 16  TLoss: 7.795    Best_HMean:  0.287 ACC_seen: 0.280, ACC_unseen: 0.278\n",
      "[ Epoch: 17  TLoss: 7.775    Best_HMean:  0.287 ACC_seen: 0.270, ACC_unseen: 0.275\n",
      "[ Epoch: 18  TLoss: 7.770    Best_HMean:  0.287 ACC_seen: 0.274, ACC_unseen: 0.276\n",
      "[ Epoch: 19  TLoss: 7.788    Best_HMean:  0.287 ACC_seen: 0.280, ACC_unseen: 0.276\n",
      "[ Epoch: 20  TLoss: 7.740    Best_HMean:  0.287 ACC_seen: 0.282, ACC_unseen: 0.274\n",
      "[ Epoch: 21  TLoss: 7.777    Best_HMean:  0.287 ACC_seen: 0.283, ACC_unseen: 0.273\n",
      "[ Epoch: 22  TLoss: 7.771    Best_HMean:  0.287 ACC_seen: 0.284, ACC_unseen: 0.273\n",
      "[ Epoch: 23  TLoss: 7.772    Best_HMean:  0.287 ACC_seen: 0.281, ACC_unseen: 0.272\n",
      "[ Epoch: 24  TLoss: 7.792    Best_HMean:  0.287 ACC_seen: 0.283, ACC_unseen: 0.274\n",
      "[ Epoch: 25  TLoss: 7.773    Best_HMean:  0.287 ACC_seen: 0.284, ACC_unseen: 0.274\n",
      "[ Epoch: 26  TLoss: 7.755    Best_HMean:  0.287 ACC_seen: 0.284, ACC_unseen: 0.276\n",
      "[ Epoch: 27  TLoss: 7.732    Best_HMean:  0.287 ACC_seen: 0.281, ACC_unseen: 0.277\n",
      "[ Epoch: 28  TLoss: 7.746    Best_HMean:  0.287 ACC_seen: 0.280, ACC_unseen: 0.279\n",
      "[ Epoch: 29  TLoss: 7.724    Best_HMean:  0.287 ACC_seen: 0.280, ACC_unseen: 0.281\n",
      "[ Epoch: 30  TLoss: 7.723    Best_HMean:  0.287 ACC_seen: 0.280, ACC_unseen: 0.281\n",
      "[ Epoch: 31  TLoss: 7.734    Best_HMean:  0.287 ACC_seen: 0.280, ACC_unseen: 0.281\n",
      "[ Epoch: 32  TLoss: 7.757    Best_HMean:  0.287 ACC_seen: 0.280, ACC_unseen: 0.281\n",
      "[ Epoch: 33  TLoss: 7.703    Best_HMean:  0.287 ACC_seen: 0.280, ACC_unseen: 0.282\n",
      "[ Epoch: 34  TLoss: 7.708    Best_HMean:  0.287 ACC_seen: 0.279, ACC_unseen: 0.282\n",
      "[ Epoch: 35  TLoss: 7.733    Best_HMean:  0.287 ACC_seen: 0.279, ACC_unseen: 0.283\n",
      "[ Epoch: 36  TLoss: 7.726    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.282\n",
      "[ Epoch: 37  TLoss: 7.746    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 38  TLoss: 7.726    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 39  TLoss: 7.700    Best_HMean:  0.287 ACC_seen: 0.275, ACC_unseen: 0.284\n",
      "[ Epoch: 40  TLoss: 7.702    Best_HMean:  0.287 ACC_seen: 0.275, ACC_unseen: 0.284\n",
      "[ Epoch: 41  TLoss: 7.715    Best_HMean:  0.287 ACC_seen: 0.275, ACC_unseen: 0.284\n",
      "[ Epoch: 42  TLoss: 7.734    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.284\n",
      "[ Epoch: 43  TLoss: 7.710    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.284\n",
      "[ Epoch: 44  TLoss: 7.739    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.284\n",
      "[ Epoch: 45  TLoss: 7.716    Best_HMean:  0.287 ACC_seen: 0.275, ACC_unseen: 0.285\n",
      "[ Epoch: 46  TLoss: 7.717    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.285\n",
      "[ Epoch: 47  TLoss: 7.726    Best_HMean:  0.287 ACC_seen: 0.275, ACC_unseen: 0.285\n",
      "[ Epoch: 48  TLoss: 7.706    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 49  TLoss: 7.717    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 50  TLoss: 7.693    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 51  TLoss: 7.712    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 52  TLoss: 7.725    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 53  TLoss: 7.719    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 54  TLoss: 7.712    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.286\n",
      "[ Epoch: 55  TLoss: 7.702    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.286\n",
      "[ Epoch: 56  TLoss: 7.696    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.286\n",
      "[ Epoch: 57  TLoss: 7.714    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.286\n",
      "[ Epoch: 58  TLoss: 7.709    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.286\n",
      "[ Epoch: 59  TLoss: 7.718    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.285\n",
      "[ Epoch: 60  TLoss: 7.703    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.285\n",
      "[ Epoch: 61  TLoss: 7.735    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.285\n",
      "[ Epoch: 62  TLoss: 7.705    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.285\n",
      "[ Epoch: 63  TLoss: 7.720    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 64  TLoss: 7.694    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 65  TLoss: 7.705    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 66  TLoss: 7.715    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 67  TLoss: 7.700    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.285\n",
      "[ Epoch: 68  TLoss: 7.710    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.285\n",
      "[ Epoch: 69  TLoss: 7.710    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 70  TLoss: 7.714    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 71  TLoss: 7.708    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 72  TLoss: 7.715    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.285\n",
      "[ Epoch: 73  TLoss: 7.702    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 74  TLoss: 7.713    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 75  TLoss: 7.722    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 76  TLoss: 7.687    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 77  TLoss: 7.712    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 78  TLoss: 7.709    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 79  TLoss: 7.710    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 80  TLoss: 7.710    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 81  TLoss: 7.723    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 82  TLoss: 7.714    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 83  TLoss: 7.710    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 84  TLoss: 7.713    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 85  TLoss: 7.690    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 86  TLoss: 7.706    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 87  TLoss: 7.712    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 88  TLoss: 7.715    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 89  TLoss: 7.698    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 90  TLoss: 7.695    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 91  TLoss: 7.711    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 92  TLoss: 7.713    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 93  TLoss: 7.700    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 94  TLoss: 7.691    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 95  TLoss: 7.702    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 96  TLoss: 7.704    Best_HMean:  0.287 ACC_seen: 0.277, ACC_unseen: 0.284\n",
      "[ Epoch: 97  TLoss: 7.698    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.284\n",
      "[ Epoch: 98  TLoss: 7.708    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.284\n",
      "[ Epoch: 99  TLoss: 7.725    Best_HMean:  0.287 ACC_seen: 0.276, ACC_unseen: 0.284\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233], [0.26659650816827546, 0.1833332416667125, 0.2172605926922656], [0.29156026543504593, 0.2041665645833844, 0.24015991936801118], [0.29192475565473125, 0.22175914837968508, 0.2520498878649059], [0.3149413446758019, 0.23463529934901697, 0.2689210230777258], [0.32659144220220343, 0.2630951065476848, 0.2914246915277531], [0.30462223654886766, 0.27187486406256794, 0.28731845854669674]]\n",
      "\n",
      "<=============== Training task 9===============>\n",
      "current_task_class[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476]\n",
      "task_testseen_class: (477,)\n",
      "task_testunseen_class: (240,)\n",
      "[ Epoch: 0  TLoss: 8.055    Best_HMean:  0.307 ACC_seen: 0.335, ACC_unseen: 0.283\n",
      "[ Epoch: 1  TLoss: 8.013    Best_HMean:  0.307 ACC_seen: 0.320, ACC_unseen: 0.277\n",
      "[ Epoch: 2  TLoss: 8.030    Best_HMean:  0.307 ACC_seen: 0.315, ACC_unseen: 0.277\n",
      "[ Epoch: 3  TLoss: 7.992    Best_HMean:  0.307 ACC_seen: 0.315, ACC_unseen: 0.276\n",
      "[ Epoch: 4  TLoss: 7.940    Best_HMean:  0.307 ACC_seen: 0.324, ACC_unseen: 0.284\n",
      "[ Epoch: 5  TLoss: 7.921    Best_HMean:  0.307 ACC_seen: 0.321, ACC_unseen: 0.284\n",
      "[ Epoch: 6  TLoss: 7.932    Best_HMean:  0.307 ACC_seen: 0.316, ACC_unseen: 0.280\n",
      "[ Epoch: 7  TLoss: 7.906    Best_HMean:  0.307 ACC_seen: 0.310, ACC_unseen: 0.287\n",
      "[ Epoch: 8  TLoss: 7.938    Best_HMean:  0.307 ACC_seen: 0.304, ACC_unseen: 0.290\n",
      "[ Epoch: 9  TLoss: 7.880    Best_HMean:  0.307 ACC_seen: 0.297, ACC_unseen: 0.295\n",
      "[ Epoch: 10  TLoss: 7.918    Best_HMean:  0.307 ACC_seen: 0.303, ACC_unseen: 0.291\n",
      "[ Epoch: 11  TLoss: 7.890    Best_HMean:  0.307 ACC_seen: 0.299, ACC_unseen: 0.289\n",
      "[ Epoch: 12  TLoss: 7.886    Best_HMean:  0.307 ACC_seen: 0.303, ACC_unseen: 0.291\n",
      "[ Epoch: 13  TLoss: 7.903    Best_HMean:  0.307 ACC_seen: 0.300, ACC_unseen: 0.293\n",
      "[ Epoch: 14  TLoss: 7.854    Best_HMean:  0.307 ACC_seen: 0.296, ACC_unseen: 0.292\n",
      "[ Epoch: 15  TLoss: 7.872    Best_HMean:  0.307 ACC_seen: 0.300, ACC_unseen: 0.299\n",
      "[ Epoch: 16  TLoss: 7.901    Best_HMean:  0.307 ACC_seen: 0.295, ACC_unseen: 0.296\n",
      "[ Epoch: 17  TLoss: 7.865    Best_HMean:  0.307 ACC_seen: 0.290, ACC_unseen: 0.297\n",
      "[ Epoch: 18  TLoss: 7.858    Best_HMean:  0.307 ACC_seen: 0.291, ACC_unseen: 0.296\n",
      "[ Epoch: 19  TLoss: 7.854    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.296\n",
      "[ Epoch: 20  TLoss: 7.881    Best_HMean:  0.307 ACC_seen: 0.291, ACC_unseen: 0.295\n",
      "[ Epoch: 21  TLoss: 7.855    Best_HMean:  0.307 ACC_seen: 0.296, ACC_unseen: 0.296\n",
      "[ Epoch: 22  TLoss: 7.877    Best_HMean:  0.307 ACC_seen: 0.290, ACC_unseen: 0.298\n",
      "[ Epoch: 23  TLoss: 7.869    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.295\n",
      "[ Epoch: 24  TLoss: 7.882    Best_HMean:  0.307 ACC_seen: 0.292, ACC_unseen: 0.293\n",
      "[ Epoch: 25  TLoss: 7.846    Best_HMean:  0.307 ACC_seen: 0.291, ACC_unseen: 0.293\n",
      "[ Epoch: 26  TLoss: 7.840    Best_HMean:  0.307 ACC_seen: 0.292, ACC_unseen: 0.293\n",
      "[ Epoch: 27  TLoss: 7.875    Best_HMean:  0.307 ACC_seen: 0.289, ACC_unseen: 0.294\n",
      "[ Epoch: 28  TLoss: 7.842    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.296\n",
      "[ Epoch: 29  TLoss: 7.841    Best_HMean:  0.307 ACC_seen: 0.283, ACC_unseen: 0.299\n",
      "[ Epoch: 30  TLoss: 7.851    Best_HMean:  0.307 ACC_seen: 0.283, ACC_unseen: 0.299\n",
      "[ Epoch: 31  TLoss: 7.829    Best_HMean:  0.307 ACC_seen: 0.285, ACC_unseen: 0.300\n",
      "[ Epoch: 32  TLoss: 7.806    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.300\n",
      "[ Epoch: 33  TLoss: 7.791    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.301\n",
      "[ Epoch: 34  TLoss: 7.814    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.302\n",
      "[ Epoch: 35  TLoss: 7.814    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.302\n",
      "[ Epoch: 36  TLoss: 7.799    Best_HMean:  0.307 ACC_seen: 0.289, ACC_unseen: 0.303\n",
      "[ Epoch: 37  TLoss: 7.812    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 38  TLoss: 7.819    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.302\n",
      "[ Epoch: 39  TLoss: 7.783    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.302\n",
      "[ Epoch: 40  TLoss: 7.824    Best_HMean:  0.307 ACC_seen: 0.291, ACC_unseen: 0.302\n",
      "[ Epoch: 41  TLoss: 7.827    Best_HMean:  0.307 ACC_seen: 0.291, ACC_unseen: 0.300\n",
      "[ Epoch: 42  TLoss: 7.775    Best_HMean:  0.307 ACC_seen: 0.289, ACC_unseen: 0.300\n",
      "[ Epoch: 43  TLoss: 7.789    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.299\n",
      "[ Epoch: 44  TLoss: 7.818    Best_HMean:  0.307 ACC_seen: 0.285, ACC_unseen: 0.300\n",
      "[ Epoch: 45  TLoss: 7.797    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.300\n",
      "[ Epoch: 46  TLoss: 7.823    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.299\n",
      "[ Epoch: 47  TLoss: 7.789    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.299\n",
      "[ Epoch: 48  TLoss: 7.812    Best_HMean:  0.307 ACC_seen: 0.285, ACC_unseen: 0.300\n",
      "[ Epoch: 49  TLoss: 7.806    Best_HMean:  0.307 ACC_seen: 0.284, ACC_unseen: 0.299\n",
      "[ Epoch: 50  TLoss: 7.790    Best_HMean:  0.307 ACC_seen: 0.284, ACC_unseen: 0.300\n",
      "[ Epoch: 51  TLoss: 7.804    Best_HMean:  0.307 ACC_seen: 0.284, ACC_unseen: 0.300\n",
      "[ Epoch: 52  TLoss: 7.788    Best_HMean:  0.307 ACC_seen: 0.284, ACC_unseen: 0.300\n",
      "[ Epoch: 53  TLoss: 7.810    Best_HMean:  0.307 ACC_seen: 0.285, ACC_unseen: 0.300\n",
      "[ Epoch: 54  TLoss: 7.785    Best_HMean:  0.307 ACC_seen: 0.285, ACC_unseen: 0.300\n",
      "[ Epoch: 55  TLoss: 7.820    Best_HMean:  0.307 ACC_seen: 0.285, ACC_unseen: 0.300\n",
      "[ Epoch: 56  TLoss: 7.792    Best_HMean:  0.307 ACC_seen: 0.284, ACC_unseen: 0.301\n",
      "[ Epoch: 57  TLoss: 7.791    Best_HMean:  0.307 ACC_seen: 0.285, ACC_unseen: 0.300\n",
      "[ Epoch: 58  TLoss: 7.812    Best_HMean:  0.307 ACC_seen: 0.285, ACC_unseen: 0.301\n",
      "[ Epoch: 59  TLoss: 7.781    Best_HMean:  0.307 ACC_seen: 0.285, ACC_unseen: 0.300\n",
      "[ Epoch: 60  TLoss: 7.786    Best_HMean:  0.307 ACC_seen: 0.285, ACC_unseen: 0.299\n",
      "[ Epoch: 61  TLoss: 7.797    Best_HMean:  0.307 ACC_seen: 0.285, ACC_unseen: 0.299\n",
      "[ Epoch: 62  TLoss: 7.795    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.299\n",
      "[ Epoch: 63  TLoss: 7.795    Best_HMean:  0.307 ACC_seen: 0.285, ACC_unseen: 0.299\n",
      "[ Epoch: 64  TLoss: 7.803    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.299\n",
      "[ Epoch: 65  TLoss: 7.796    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.298\n",
      "[ Epoch: 66  TLoss: 7.808    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.298\n",
      "[ Epoch: 67  TLoss: 7.794    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.298\n",
      "[ Epoch: 68  TLoss: 7.788    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.298\n",
      "[ Epoch: 69  TLoss: 7.788    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.298\n",
      "[ Epoch: 70  TLoss: 7.792    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.299\n",
      "[ Epoch: 71  TLoss: 7.803    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.299\n",
      "[ Epoch: 72  TLoss: 7.801    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.299\n",
      "[ Epoch: 73  TLoss: 7.812    Best_HMean:  0.307 ACC_seen: 0.286, ACC_unseen: 0.300\n",
      "[ Epoch: 74  TLoss: 7.790    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.300\n",
      "[ Epoch: 75  TLoss: 7.810    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.300\n",
      "[ Epoch: 76  TLoss: 7.777    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.300\n",
      "[ Epoch: 77  TLoss: 7.825    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.300\n",
      "[ Epoch: 78  TLoss: 7.805    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.300\n",
      "[ Epoch: 79  TLoss: 7.791    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.300\n",
      "[ Epoch: 80  TLoss: 7.788    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.300\n",
      "[ Epoch: 81  TLoss: 7.808    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.300\n",
      "[ Epoch: 82  TLoss: 7.782    Best_HMean:  0.307 ACC_seen: 0.289, ACC_unseen: 0.300\n",
      "[ Epoch: 83  TLoss: 7.792    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.300\n",
      "[ Epoch: 84  TLoss: 7.812    Best_HMean:  0.307 ACC_seen: 0.289, ACC_unseen: 0.300\n",
      "[ Epoch: 85  TLoss: 7.797    Best_HMean:  0.307 ACC_seen: 0.289, ACC_unseen: 0.300\n",
      "[ Epoch: 86  TLoss: 7.799    Best_HMean:  0.307 ACC_seen: 0.289, ACC_unseen: 0.300\n",
      "[ Epoch: 87  TLoss: 7.796    Best_HMean:  0.307 ACC_seen: 0.289, ACC_unseen: 0.300\n",
      "[ Epoch: 88  TLoss: 7.802    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.300\n",
      "[ Epoch: 89  TLoss: 7.814    Best_HMean:  0.307 ACC_seen: 0.288, ACC_unseen: 0.300\n",
      "[ Epoch: 90  TLoss: 7.803    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.300\n",
      "[ Epoch: 91  TLoss: 7.813    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.299\n",
      "[ Epoch: 92  TLoss: 7.783    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.299\n",
      "[ Epoch: 93  TLoss: 7.806    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.299\n",
      "[ Epoch: 94  TLoss: 7.798    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.299\n",
      "[ Epoch: 95  TLoss: 7.799    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.299\n",
      "[ Epoch: 96  TLoss: 7.775    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.299\n",
      "[ Epoch: 97  TLoss: 7.804    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.300\n",
      "[ Epoch: 98  TLoss: 7.797    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.299\n",
      "[ Epoch: 99  TLoss: 7.804    Best_HMean:  0.307 ACC_seen: 0.287, ACC_unseen: 0.299\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233], [0.26659650816827546, 0.1833332416667125, 0.2172605926922656], [0.29156026543504593, 0.2041665645833844, 0.24015991936801118], [0.29192475565473125, 0.22175914837968508, 0.2520498878649059], [0.3149413446758019, 0.23463529934901697, 0.2689210230777258], [0.32659144220220343, 0.2630951065476848, 0.2914246915277531], [0.30462223654886766, 0.27187486406256794, 0.28731845854669674], [0.3347007995023005, 0.28312485843757074, 0.306760055236337]]\n",
      "\n",
      "<=============== Training task 10===============>\n",
      "current_task_class[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524]\n",
      "task_testseen_class: (525,)\n",
      "task_testunseen_class: (192,)\n",
      "[ Epoch: 0  TLoss: 8.067    Best_HMean:  0.310 ACC_seen: 0.323, ACC_unseen: 0.299\n",
      "[ Epoch: 1  TLoss: 8.111    Best_HMean:  0.310 ACC_seen: 0.315, ACC_unseen: 0.304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 2  TLoss: 8.091    Best_HMean:  0.311 ACC_seen: 0.317, ACC_unseen: 0.305\n",
      "[ Epoch: 3  TLoss: 8.047    Best_HMean:  0.311 ACC_seen: 0.315, ACC_unseen: 0.301\n",
      "[ Epoch: 4  TLoss: 8.047    Best_HMean:  0.311 ACC_seen: 0.315, ACC_unseen: 0.300\n",
      "[ Epoch: 5  TLoss: 8.026    Best_HMean:  0.311 ACC_seen: 0.310, ACC_unseen: 0.302\n",
      "[ Epoch: 6  TLoss: 8.006    Best_HMean:  0.311 ACC_seen: 0.315, ACC_unseen: 0.307\n",
      "[ Epoch: 7  TLoss: 8.024    Best_HMean:  0.314 ACC_seen: 0.321, ACC_unseen: 0.307\n",
      "[ Epoch: 8  TLoss: 7.968    Best_HMean:  0.314 ACC_seen: 0.322, ACC_unseen: 0.307\n",
      "[ Epoch: 9  TLoss: 7.978    Best_HMean:  0.314 ACC_seen: 0.317, ACC_unseen: 0.306\n",
      "[ Epoch: 10  TLoss: 7.993    Best_HMean:  0.314 ACC_seen: 0.318, ACC_unseen: 0.306\n",
      "[ Epoch: 11  TLoss: 7.981    Best_HMean:  0.314 ACC_seen: 0.311, ACC_unseen: 0.314\n",
      "[ Epoch: 12  TLoss: 7.995    Best_HMean:  0.314 ACC_seen: 0.309, ACC_unseen: 0.315\n",
      "[ Epoch: 13  TLoss: 7.971    Best_HMean:  0.314 ACC_seen: 0.304, ACC_unseen: 0.315\n",
      "[ Epoch: 14  TLoss: 7.949    Best_HMean:  0.314 ACC_seen: 0.311, ACC_unseen: 0.312\n",
      "[ Epoch: 15  TLoss: 7.974    Best_HMean:  0.314 ACC_seen: 0.305, ACC_unseen: 0.310\n",
      "[ Epoch: 16  TLoss: 7.963    Best_HMean:  0.314 ACC_seen: 0.317, ACC_unseen: 0.309\n",
      "[ Epoch: 17  TLoss: 7.957    Best_HMean:  0.314 ACC_seen: 0.308, ACC_unseen: 0.308\n",
      "[ Epoch: 18  TLoss: 7.971    Best_HMean:  0.314 ACC_seen: 0.301, ACC_unseen: 0.313\n",
      "[ Epoch: 19  TLoss: 7.944    Best_HMean:  0.314 ACC_seen: 0.304, ACC_unseen: 0.313\n",
      "[ Epoch: 20  TLoss: 7.945    Best_HMean:  0.314 ACC_seen: 0.305, ACC_unseen: 0.314\n",
      "[ Epoch: 21  TLoss: 7.980    Best_HMean:  0.314 ACC_seen: 0.296, ACC_unseen: 0.318\n",
      "[ Epoch: 22  TLoss: 7.928    Best_HMean:  0.314 ACC_seen: 0.295, ACC_unseen: 0.317\n",
      "[ Epoch: 23  TLoss: 7.928    Best_HMean:  0.314 ACC_seen: 0.297, ACC_unseen: 0.319\n",
      "[ Epoch: 24  TLoss: 7.983    Best_HMean:  0.314 ACC_seen: 0.307, ACC_unseen: 0.312\n",
      "[ Epoch: 25  TLoss: 7.942    Best_HMean:  0.314 ACC_seen: 0.306, ACC_unseen: 0.315\n",
      "[ Epoch: 26  TLoss: 7.906    Best_HMean:  0.314 ACC_seen: 0.307, ACC_unseen: 0.316\n",
      "[ Epoch: 27  TLoss: 7.912    Best_HMean:  0.314 ACC_seen: 0.304, ACC_unseen: 0.318\n",
      "[ Epoch: 28  TLoss: 7.921    Best_HMean:  0.314 ACC_seen: 0.302, ACC_unseen: 0.322\n",
      "[ Epoch: 29  TLoss: 7.916    Best_HMean:  0.314 ACC_seen: 0.304, ACC_unseen: 0.322\n",
      "[ Epoch: 30  TLoss: 7.930    Best_HMean:  0.314 ACC_seen: 0.305, ACC_unseen: 0.323\n",
      "[ Epoch: 31  TLoss: 7.891    Best_HMean:  0.314 ACC_seen: 0.305, ACC_unseen: 0.322\n",
      "[ Epoch: 32  TLoss: 7.902    Best_HMean:  0.314 ACC_seen: 0.305, ACC_unseen: 0.320\n",
      "[ Epoch: 33  TLoss: 7.917    Best_HMean:  0.314 ACC_seen: 0.307, ACC_unseen: 0.322\n",
      "[ Epoch: 34  TLoss: 7.919    Best_HMean:  0.315 ACC_seen: 0.308, ACC_unseen: 0.323\n",
      "[ Epoch: 35  TLoss: 7.901    Best_HMean:  0.315 ACC_seen: 0.305, ACC_unseen: 0.322\n",
      "[ Epoch: 36  TLoss: 7.901    Best_HMean:  0.315 ACC_seen: 0.305, ACC_unseen: 0.319\n",
      "[ Epoch: 37  TLoss: 7.906    Best_HMean:  0.315 ACC_seen: 0.306, ACC_unseen: 0.319\n",
      "[ Epoch: 38  TLoss: 7.908    Best_HMean:  0.315 ACC_seen: 0.306, ACC_unseen: 0.319\n",
      "[ Epoch: 39  TLoss: 7.895    Best_HMean:  0.315 ACC_seen: 0.305, ACC_unseen: 0.320\n",
      "[ Epoch: 40  TLoss: 7.905    Best_HMean:  0.315 ACC_seen: 0.305, ACC_unseen: 0.320\n",
      "[ Epoch: 41  TLoss: 7.899    Best_HMean:  0.315 ACC_seen: 0.305, ACC_unseen: 0.321\n",
      "[ Epoch: 42  TLoss: 7.907    Best_HMean:  0.315 ACC_seen: 0.306, ACC_unseen: 0.320\n",
      "[ Epoch: 43  TLoss: 7.907    Best_HMean:  0.315 ACC_seen: 0.305, ACC_unseen: 0.321\n",
      "[ Epoch: 44  TLoss: 7.876    Best_HMean:  0.315 ACC_seen: 0.306, ACC_unseen: 0.320\n",
      "[ Epoch: 45  TLoss: 7.897    Best_HMean:  0.315 ACC_seen: 0.305, ACC_unseen: 0.321\n",
      "[ Epoch: 46  TLoss: 7.899    Best_HMean:  0.315 ACC_seen: 0.305, ACC_unseen: 0.320\n",
      "[ Epoch: 47  TLoss: 7.899    Best_HMean:  0.315 ACC_seen: 0.301, ACC_unseen: 0.318\n",
      "[ Epoch: 48  TLoss: 7.888    Best_HMean:  0.315 ACC_seen: 0.303, ACC_unseen: 0.317\n",
      "[ Epoch: 49  TLoss: 7.906    Best_HMean:  0.315 ACC_seen: 0.303, ACC_unseen: 0.317\n",
      "[ Epoch: 50  TLoss: 7.903    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.316\n",
      "[ Epoch: 51  TLoss: 7.894    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.316\n",
      "[ Epoch: 52  TLoss: 7.895    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.316\n",
      "[ Epoch: 53  TLoss: 7.873    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.317\n",
      "[ Epoch: 54  TLoss: 7.895    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.317\n",
      "[ Epoch: 55  TLoss: 7.894    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.317\n",
      "[ Epoch: 56  TLoss: 7.885    Best_HMean:  0.315 ACC_seen: 0.303, ACC_unseen: 0.318\n",
      "[ Epoch: 57  TLoss: 7.894    Best_HMean:  0.315 ACC_seen: 0.303, ACC_unseen: 0.318\n",
      "[ Epoch: 58  TLoss: 7.899    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.318\n",
      "[ Epoch: 59  TLoss: 7.881    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.318\n",
      "[ Epoch: 60  TLoss: 7.887    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.318\n",
      "[ Epoch: 61  TLoss: 7.913    Best_HMean:  0.315 ACC_seen: 0.303, ACC_unseen: 0.317\n",
      "[ Epoch: 62  TLoss: 7.902    Best_HMean:  0.315 ACC_seen: 0.303, ACC_unseen: 0.317\n",
      "[ Epoch: 63  TLoss: 7.894    Best_HMean:  0.315 ACC_seen: 0.303, ACC_unseen: 0.317\n",
      "[ Epoch: 64  TLoss: 7.897    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.318\n",
      "[ Epoch: 65  TLoss: 7.891    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.318\n",
      "[ Epoch: 66  TLoss: 7.904    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.318\n",
      "[ Epoch: 67  TLoss: 7.870    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.318\n",
      "[ Epoch: 68  TLoss: 7.885    Best_HMean:  0.315 ACC_seen: 0.302, ACC_unseen: 0.319\n",
      "[ Epoch: 69  TLoss: 7.903    Best_HMean:  0.315 ACC_seen: 0.303, ACC_unseen: 0.319\n",
      "[ Epoch: 70  TLoss: 7.891    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.319\n",
      "[ Epoch: 71  TLoss: 7.891    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.319\n",
      "[ Epoch: 72  TLoss: 7.896    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.319\n",
      "[ Epoch: 73  TLoss: 7.904    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.318\n",
      "[ Epoch: 74  TLoss: 7.910    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.318\n",
      "[ Epoch: 75  TLoss: 7.884    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.318\n",
      "[ Epoch: 76  TLoss: 7.885    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.318\n",
      "[ Epoch: 77  TLoss: 7.879    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.318\n",
      "[ Epoch: 78  TLoss: 7.912    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.318\n",
      "[ Epoch: 79  TLoss: 7.886    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.318\n",
      "[ Epoch: 80  TLoss: 7.903    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.318\n",
      "[ Epoch: 81  TLoss: 7.901    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.318\n",
      "[ Epoch: 82  TLoss: 7.891    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.319\n",
      "[ Epoch: 83  TLoss: 7.896    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.318\n",
      "[ Epoch: 84  TLoss: 7.877    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.319\n",
      "[ Epoch: 85  TLoss: 7.883    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.319\n",
      "[ Epoch: 86  TLoss: 7.880    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.319\n",
      "[ Epoch: 87  TLoss: 7.894    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.319\n",
      "[ Epoch: 88  TLoss: 7.886    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.319\n",
      "[ Epoch: 89  TLoss: 7.893    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.319\n",
      "[ Epoch: 90  TLoss: 7.903    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.319\n",
      "[ Epoch: 91  TLoss: 7.905    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.319\n",
      "[ Epoch: 92  TLoss: 7.887    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.320\n",
      "[ Epoch: 93  TLoss: 7.900    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.320\n",
      "[ Epoch: 94  TLoss: 7.880    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.320\n",
      "[ Epoch: 95  TLoss: 7.878    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.320\n",
      "[ Epoch: 96  TLoss: 7.873    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.320\n",
      "[ Epoch: 97  TLoss: 7.877    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.320\n",
      "[ Epoch: 98  TLoss: 7.884    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.320\n",
      "[ Epoch: 99  TLoss: 7.901    Best_HMean:  0.315 ACC_seen: 0.304, ACC_unseen: 0.320\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233], [0.26659650816827546, 0.1833332416667125, 0.2172605926922656], [0.29156026543504593, 0.2041665645833844, 0.24015991936801118], [0.29192475565473125, 0.22175914837968508, 0.2520498878649059], [0.3149413446758019, 0.23463529934901697, 0.2689210230777258], [0.32659144220220343, 0.2630951065476848, 0.2914246915277531], [0.30462223654886766, 0.27187486406256794, 0.28731845854669674], [0.3347007995023005, 0.28312485843757074, 0.306760055236337], [0.3083210300133327, 0.32265608867195567, 0.3153257214990356]]\n",
      "\n",
      "<=============== Training task 11===============>\n",
      "current_task_class[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572]\n",
      "task_testseen_class: (573,)\n",
      "task_testunseen_class: (144,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 0  TLoss: 8.484    Best_HMean:  0.307 ACC_seen: 0.311, ACC_unseen: 0.303\n",
      "[ Epoch: 1  TLoss: 8.374    Best_HMean:  0.311 ACC_seen: 0.324, ACC_unseen: 0.299\n",
      "[ Epoch: 2  TLoss: 8.306    Best_HMean:  0.317 ACC_seen: 0.327, ACC_unseen: 0.308\n",
      "[ Epoch: 3  TLoss: 8.279    Best_HMean:  0.317 ACC_seen: 0.320, ACC_unseen: 0.301\n",
      "[ Epoch: 4  TLoss: 8.236    Best_HMean:  0.317 ACC_seen: 0.317, ACC_unseen: 0.299\n",
      "[ Epoch: 5  TLoss: 8.202    Best_HMean:  0.317 ACC_seen: 0.323, ACC_unseen: 0.298\n",
      "[ Epoch: 6  TLoss: 8.193    Best_HMean:  0.317 ACC_seen: 0.322, ACC_unseen: 0.301\n",
      "[ Epoch: 7  TLoss: 8.172    Best_HMean:  0.317 ACC_seen: 0.324, ACC_unseen: 0.294\n",
      "[ Epoch: 8  TLoss: 8.155    Best_HMean:  0.317 ACC_seen: 0.320, ACC_unseen: 0.296\n",
      "[ Epoch: 9  TLoss: 8.155    Best_HMean:  0.317 ACC_seen: 0.319, ACC_unseen: 0.300\n",
      "[ Epoch: 10  TLoss: 8.129    Best_HMean:  0.317 ACC_seen: 0.313, ACC_unseen: 0.298\n",
      "[ Epoch: 11  TLoss: 8.132    Best_HMean:  0.317 ACC_seen: 0.311, ACC_unseen: 0.300\n",
      "[ Epoch: 12  TLoss: 8.131    Best_HMean:  0.317 ACC_seen: 0.308, ACC_unseen: 0.303\n",
      "[ Epoch: 13  TLoss: 8.128    Best_HMean:  0.317 ACC_seen: 0.309, ACC_unseen: 0.309\n",
      "[ Epoch: 14  TLoss: 8.126    Best_HMean:  0.317 ACC_seen: 0.312, ACC_unseen: 0.307\n",
      "[ Epoch: 15  TLoss: 8.121    Best_HMean:  0.317 ACC_seen: 0.309, ACC_unseen: 0.317\n",
      "[ Epoch: 16  TLoss: 8.120    Best_HMean:  0.317 ACC_seen: 0.311, ACC_unseen: 0.319\n",
      "[ Epoch: 17  TLoss: 8.098    Best_HMean:  0.317 ACC_seen: 0.306, ACC_unseen: 0.315\n",
      "[ Epoch: 18  TLoss: 8.104    Best_HMean:  0.317 ACC_seen: 0.305, ACC_unseen: 0.311\n",
      "[ Epoch: 19  TLoss: 8.097    Best_HMean:  0.317 ACC_seen: 0.302, ACC_unseen: 0.316\n",
      "[ Epoch: 20  TLoss: 8.099    Best_HMean:  0.317 ACC_seen: 0.305, ACC_unseen: 0.318\n",
      "[ Epoch: 21  TLoss: 8.110    Best_HMean:  0.317 ACC_seen: 0.302, ACC_unseen: 0.318\n",
      "[ Epoch: 22  TLoss: 8.102    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.319\n",
      "[ Epoch: 23  TLoss: 8.092    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.318\n",
      "[ Epoch: 24  TLoss: 8.089    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.321\n",
      "[ Epoch: 25  TLoss: 8.088    Best_HMean:  0.317 ACC_seen: 0.298, ACC_unseen: 0.322\n",
      "[ Epoch: 26  TLoss: 8.079    Best_HMean:  0.317 ACC_seen: 0.299, ACC_unseen: 0.323\n",
      "[ Epoch: 27  TLoss: 8.076    Best_HMean:  0.317 ACC_seen: 0.297, ACC_unseen: 0.323\n",
      "[ Epoch: 28  TLoss: 8.054    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.324\n",
      "[ Epoch: 29  TLoss: 8.061    Best_HMean:  0.317 ACC_seen: 0.299, ACC_unseen: 0.325\n",
      "[ Epoch: 30  TLoss: 8.068    Best_HMean:  0.317 ACC_seen: 0.299, ACC_unseen: 0.324\n",
      "[ Epoch: 31  TLoss: 8.038    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.325\n",
      "[ Epoch: 32  TLoss: 8.053    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 33  TLoss: 8.055    Best_HMean:  0.317 ACC_seen: 0.303, ACC_unseen: 0.323\n",
      "[ Epoch: 34  TLoss: 8.056    Best_HMean:  0.317 ACC_seen: 0.304, ACC_unseen: 0.324\n",
      "[ Epoch: 35  TLoss: 8.057    Best_HMean:  0.317 ACC_seen: 0.304, ACC_unseen: 0.325\n",
      "[ Epoch: 36  TLoss: 8.049    Best_HMean:  0.317 ACC_seen: 0.305, ACC_unseen: 0.324\n",
      "[ Epoch: 37  TLoss: 8.045    Best_HMean:  0.317 ACC_seen: 0.303, ACC_unseen: 0.324\n",
      "[ Epoch: 38  TLoss: 8.053    Best_HMean:  0.317 ACC_seen: 0.302, ACC_unseen: 0.325\n",
      "[ Epoch: 39  TLoss: 8.036    Best_HMean:  0.317 ACC_seen: 0.303, ACC_unseen: 0.324\n",
      "[ Epoch: 40  TLoss: 8.047    Best_HMean:  0.317 ACC_seen: 0.304, ACC_unseen: 0.324\n",
      "[ Epoch: 41  TLoss: 8.042    Best_HMean:  0.317 ACC_seen: 0.302, ACC_unseen: 0.323\n",
      "[ Epoch: 42  TLoss: 8.051    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 43  TLoss: 8.053    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.321\n",
      "[ Epoch: 44  TLoss: 8.080    Best_HMean:  0.317 ACC_seen: 0.302, ACC_unseen: 0.321\n",
      "[ Epoch: 45  TLoss: 8.035    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 46  TLoss: 8.040    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 47  TLoss: 8.045    Best_HMean:  0.317 ACC_seen: 0.299, ACC_unseen: 0.324\n",
      "[ Epoch: 48  TLoss: 8.046    Best_HMean:  0.317 ACC_seen: 0.299, ACC_unseen: 0.322\n",
      "[ Epoch: 49  TLoss: 8.042    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.323\n",
      "[ Epoch: 50  TLoss: 8.033    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.323\n",
      "[ Epoch: 51  TLoss: 8.057    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.323\n",
      "[ Epoch: 52  TLoss: 8.038    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 53  TLoss: 8.060    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 54  TLoss: 8.034    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 55  TLoss: 8.035    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 56  TLoss: 8.018    Best_HMean:  0.317 ACC_seen: 0.302, ACC_unseen: 0.322\n",
      "[ Epoch: 57  TLoss: 8.041    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 58  TLoss: 8.040    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.323\n",
      "[ Epoch: 59  TLoss: 8.003    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.323\n",
      "[ Epoch: 60  TLoss: 8.038    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 61  TLoss: 8.044    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 62  TLoss: 8.051    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.323\n",
      "[ Epoch: 63  TLoss: 8.031    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 64  TLoss: 8.033    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 65  TLoss: 8.044    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.323\n",
      "[ Epoch: 66  TLoss: 8.032    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.323\n",
      "[ Epoch: 67  TLoss: 8.028    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 68  TLoss: 8.022    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 69  TLoss: 8.032    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 70  TLoss: 8.041    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 71  TLoss: 8.042    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 72  TLoss: 8.020    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 73  TLoss: 8.026    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.323\n",
      "[ Epoch: 74  TLoss: 8.022    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.323\n",
      "[ Epoch: 75  TLoss: 8.020    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.323\n",
      "[ Epoch: 76  TLoss: 8.018    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 77  TLoss: 8.034    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 78  TLoss: 8.037    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 79  TLoss: 8.025    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 80  TLoss: 8.036    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 81  TLoss: 8.048    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 82  TLoss: 8.044    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 83  TLoss: 8.029    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 84  TLoss: 8.035    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 85  TLoss: 8.038    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 86  TLoss: 8.035    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 87  TLoss: 8.041    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 88  TLoss: 8.033    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 89  TLoss: 8.015    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 90  TLoss: 8.027    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 91  TLoss: 8.028    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 92  TLoss: 8.017    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 93  TLoss: 8.039    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 94  TLoss: 8.031    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 95  TLoss: 8.032    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 96  TLoss: 8.046    Best_HMean:  0.317 ACC_seen: 0.300, ACC_unseen: 0.322\n",
      "[ Epoch: 97  TLoss: 8.028    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[ Epoch: 98  TLoss: 8.040    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 99  TLoss: 8.044    Best_HMean:  0.317 ACC_seen: 0.301, ACC_unseen: 0.322\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233], [0.26659650816827546, 0.1833332416667125, 0.2172605926922656], [0.29156026543504593, 0.2041665645833844, 0.24015991936801118], [0.29192475565473125, 0.22175914837968508, 0.2520498878649059], [0.3149413446758019, 0.23463529934901697, 0.2689210230777258], [0.32659144220220343, 0.2630951065476848, 0.2914246915277531], [0.30462223654886766, 0.27187486406256794, 0.28731845854669674], [0.3347007995023005, 0.28312485843757074, 0.306760055236337], [0.3083210300133327, 0.32265608867195567, 0.3153257214990356], [0.3271929207856598, 0.30833317916674374, 0.31748321107268634]]\n",
      "\n",
      "<=============== Training task 12===============>\n",
      "current_task_class[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620]\n",
      "task_testseen_class: (621,)\n",
      "task_testunseen_class: (96,)\n",
      "[ Epoch: 0  TLoss: 8.289    Best_HMean:  0.311 ACC_seen: 0.330, ACC_unseen: 0.295\n",
      "[ Epoch: 1  TLoss: 8.257    Best_HMean:  0.318 ACC_seen: 0.341, ACC_unseen: 0.298\n",
      "[ Epoch: 2  TLoss: 8.264    Best_HMean:  0.318 ACC_seen: 0.338, ACC_unseen: 0.291\n",
      "[ Epoch: 3  TLoss: 8.207    Best_HMean:  0.318 ACC_seen: 0.342, ACC_unseen: 0.289\n",
      "[ Epoch: 4  TLoss: 8.200    Best_HMean:  0.318 ACC_seen: 0.336, ACC_unseen: 0.281\n",
      "[ Epoch: 5  TLoss: 8.180    Best_HMean:  0.318 ACC_seen: 0.324, ACC_unseen: 0.285\n",
      "[ Epoch: 6  TLoss: 8.197    Best_HMean:  0.318 ACC_seen: 0.321, ACC_unseen: 0.293\n",
      "[ Epoch: 7  TLoss: 8.176    Best_HMean:  0.318 ACC_seen: 0.331, ACC_unseen: 0.297\n",
      "[ Epoch: 8  TLoss: 8.145    Best_HMean:  0.318 ACC_seen: 0.333, ACC_unseen: 0.295\n",
      "[ Epoch: 9  TLoss: 8.153    Best_HMean:  0.318 ACC_seen: 0.334, ACC_unseen: 0.300\n",
      "[ Epoch: 10  TLoss: 8.130    Best_HMean:  0.318 ACC_seen: 0.329, ACC_unseen: 0.295\n",
      "[ Epoch: 11  TLoss: 8.135    Best_HMean:  0.318 ACC_seen: 0.325, ACC_unseen: 0.292\n",
      "[ Epoch: 12  TLoss: 8.145    Best_HMean:  0.318 ACC_seen: 0.331, ACC_unseen: 0.299\n",
      "[ Epoch: 13  TLoss: 8.124    Best_HMean:  0.318 ACC_seen: 0.328, ACC_unseen: 0.302\n",
      "[ Epoch: 14  TLoss: 8.132    Best_HMean:  0.318 ACC_seen: 0.331, ACC_unseen: 0.306\n",
      "[ Epoch: 15  TLoss: 8.130    Best_HMean:  0.320 ACC_seen: 0.330, ACC_unseen: 0.311\n",
      "[ Epoch: 16  TLoss: 8.125    Best_HMean:  0.320 ACC_seen: 0.327, ACC_unseen: 0.306\n",
      "[ Epoch: 17  TLoss: 8.110    Best_HMean:  0.320 ACC_seen: 0.333, ACC_unseen: 0.303\n",
      "[ Epoch: 18  TLoss: 8.127    Best_HMean:  0.320 ACC_seen: 0.326, ACC_unseen: 0.297\n",
      "[ Epoch: 19  TLoss: 8.115    Best_HMean:  0.320 ACC_seen: 0.328, ACC_unseen: 0.296\n",
      "[ Epoch: 20  TLoss: 8.093    Best_HMean:  0.320 ACC_seen: 0.323, ACC_unseen: 0.307\n",
      "[ Epoch: 21  TLoss: 8.113    Best_HMean:  0.320 ACC_seen: 0.318, ACC_unseen: 0.311\n",
      "[ Epoch: 22  TLoss: 8.105    Best_HMean:  0.320 ACC_seen: 0.326, ACC_unseen: 0.311\n",
      "[ Epoch: 23  TLoss: 8.127    Best_HMean:  0.320 ACC_seen: 0.327, ACC_unseen: 0.308\n",
      "[ Epoch: 24  TLoss: 8.113    Best_HMean:  0.320 ACC_seen: 0.321, ACC_unseen: 0.298\n",
      "[ Epoch: 25  TLoss: 8.102    Best_HMean:  0.320 ACC_seen: 0.320, ACC_unseen: 0.299\n",
      "[ Epoch: 26  TLoss: 8.096    Best_HMean:  0.320 ACC_seen: 0.322, ACC_unseen: 0.303\n",
      "[ Epoch: 27  TLoss: 8.100    Best_HMean:  0.320 ACC_seen: 0.319, ACC_unseen: 0.307\n",
      "[ Epoch: 28  TLoss: 8.089    Best_HMean:  0.320 ACC_seen: 0.318, ACC_unseen: 0.312\n",
      "[ Epoch: 29  TLoss: 8.092    Best_HMean:  0.320 ACC_seen: 0.317, ACC_unseen: 0.313\n",
      "[ Epoch: 30  TLoss: 8.088    Best_HMean:  0.320 ACC_seen: 0.319, ACC_unseen: 0.312\n",
      "[ Epoch: 31  TLoss: 8.096    Best_HMean:  0.320 ACC_seen: 0.320, ACC_unseen: 0.313\n",
      "[ Epoch: 32  TLoss: 8.052    Best_HMean:  0.320 ACC_seen: 0.320, ACC_unseen: 0.311\n",
      "[ Epoch: 33  TLoss: 8.071    Best_HMean:  0.320 ACC_seen: 0.321, ACC_unseen: 0.309\n",
      "[ Epoch: 34  TLoss: 8.090    Best_HMean:  0.320 ACC_seen: 0.321, ACC_unseen: 0.311\n",
      "[ Epoch: 35  TLoss: 8.075    Best_HMean:  0.320 ACC_seen: 0.321, ACC_unseen: 0.311\n",
      "[ Epoch: 36  TLoss: 8.049    Best_HMean:  0.320 ACC_seen: 0.320, ACC_unseen: 0.314\n",
      "[ Epoch: 37  TLoss: 8.067    Best_HMean:  0.320 ACC_seen: 0.320, ACC_unseen: 0.314\n",
      "[ Epoch: 38  TLoss: 8.050    Best_HMean:  0.320 ACC_seen: 0.321, ACC_unseen: 0.318\n",
      "[ Epoch: 39  TLoss: 8.071    Best_HMean:  0.320 ACC_seen: 0.321, ACC_unseen: 0.320\n",
      "[ Epoch: 40  TLoss: 8.048    Best_HMean:  0.321 ACC_seen: 0.321, ACC_unseen: 0.321\n",
      "[ Epoch: 41  TLoss: 8.071    Best_HMean:  0.321 ACC_seen: 0.320, ACC_unseen: 0.319\n",
      "[ Epoch: 42  TLoss: 8.056    Best_HMean:  0.321 ACC_seen: 0.320, ACC_unseen: 0.320\n",
      "[ Epoch: 43  TLoss: 8.045    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 44  TLoss: 8.048    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.316\n",
      "[ Epoch: 45  TLoss: 8.057    Best_HMean:  0.321 ACC_seen: 0.317, ACC_unseen: 0.316\n",
      "[ Epoch: 46  TLoss: 8.043    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.317\n",
      "[ Epoch: 47  TLoss: 8.058    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.318\n",
      "[ Epoch: 48  TLoss: 8.051    Best_HMean:  0.321 ACC_seen: 0.317, ACC_unseen: 0.319\n",
      "[ Epoch: 49  TLoss: 8.050    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 50  TLoss: 8.061    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.320\n",
      "[ Epoch: 51  TLoss: 8.051    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.320\n",
      "[ Epoch: 52  TLoss: 8.040    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.319\n",
      "[ Epoch: 53  TLoss: 8.059    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 54  TLoss: 8.037    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.320\n",
      "[ Epoch: 55  TLoss: 8.060    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.319\n",
      "[ Epoch: 56  TLoss: 8.067    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 57  TLoss: 8.062    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.319\n",
      "[ Epoch: 58  TLoss: 8.056    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 59  TLoss: 8.051    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 60  TLoss: 8.049    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 61  TLoss: 8.064    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.318\n",
      "[ Epoch: 62  TLoss: 8.035    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.318\n",
      "[ Epoch: 63  TLoss: 8.047    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.319\n",
      "[ Epoch: 64  TLoss: 8.048    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 65  TLoss: 8.049    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.320\n",
      "[ Epoch: 66  TLoss: 8.061    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.320\n",
      "[ Epoch: 67  TLoss: 8.054    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.320\n",
      "[ Epoch: 68  TLoss: 8.042    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.321\n",
      "[ Epoch: 69  TLoss: 8.036    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.321\n",
      "[ Epoch: 70  TLoss: 8.063    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.320\n",
      "[ Epoch: 71  TLoss: 8.039    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.320\n",
      "[ Epoch: 72  TLoss: 8.065    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.319\n",
      "[ Epoch: 73  TLoss: 8.065    Best_HMean:  0.321 ACC_seen: 0.318, ACC_unseen: 0.319\n",
      "[ Epoch: 74  TLoss: 8.058    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 75  TLoss: 8.039    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.320\n",
      "[ Epoch: 76  TLoss: 8.041    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.320\n",
      "[ Epoch: 77  TLoss: 8.052    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.320\n",
      "[ Epoch: 78  TLoss: 8.056    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 79  TLoss: 8.052    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 80  TLoss: 8.040    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 81  TLoss: 8.045    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 82  TLoss: 8.042    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 83  TLoss: 8.055    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 84  TLoss: 8.057    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 85  TLoss: 8.052    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 86  TLoss: 8.072    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 87  TLoss: 8.055    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 88  TLoss: 8.053    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 89  TLoss: 8.049    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 90  TLoss: 8.051    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 91  TLoss: 8.052    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 92  TLoss: 8.053    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 93  TLoss: 8.039    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 94  TLoss: 8.047    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 95  TLoss: 8.045    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 96  TLoss: 8.046    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 97  TLoss: 8.058    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 98  TLoss: 8.050    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[ Epoch: 99  TLoss: 8.067    Best_HMean:  0.321 ACC_seen: 0.319, ACC_unseen: 0.319\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233], [0.26659650816827546, 0.1833332416667125, 0.2172605926922656], [0.29156026543504593, 0.2041665645833844, 0.24015991936801118], [0.29192475565473125, 0.22175914837968508, 0.2520498878649059], [0.3149413446758019, 0.23463529934901697, 0.2689210230777258], [0.32659144220220343, 0.2630951065476848, 0.2914246915277531], [0.30462223654886766, 0.27187486406256794, 0.28731845854669674], [0.3347007995023005, 0.28312485843757074, 0.306760055236337], [0.3083210300133327, 0.32265608867195567, 0.3153257214990356], [0.3271929207856598, 0.30833317916674374, 0.31748321107268634], [0.3210710408278093, 0.3208331729167469, 0.3209520627993916]]\n",
      "\n",
      "<=============== Training task 13===============>\n",
      "current_task_class[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
      " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
      " 666 667 668]\n",
      "task_testseen_class: (669,)\n",
      "task_testunseen_class: (48,)\n",
      "[ Epoch: 0  TLoss: 8.566    Best_HMean:  0.322 ACC_seen: 0.345, ACC_unseen: 0.302\n",
      "[ Epoch: 1  TLoss: 8.460    Best_HMean:  0.323 ACC_seen: 0.357, ACC_unseen: 0.295\n",
      "[ Epoch: 2  TLoss: 8.408    Best_HMean:  0.323 ACC_seen: 0.350, ACC_unseen: 0.292\n",
      "[ Epoch: 3  TLoss: 8.379    Best_HMean:  0.323 ACC_seen: 0.343, ACC_unseen: 0.299\n",
      "[ Epoch: 4  TLoss: 8.333    Best_HMean:  0.323 ACC_seen: 0.340, ACC_unseen: 0.296\n",
      "[ Epoch: 5  TLoss: 8.312    Best_HMean:  0.323 ACC_seen: 0.345, ACC_unseen: 0.301\n",
      "[ Epoch: 6  TLoss: 8.300    Best_HMean:  0.323 ACC_seen: 0.344, ACC_unseen: 0.305\n",
      "[ Epoch: 7  TLoss: 8.269    Best_HMean:  0.323 ACC_seen: 0.349, ACC_unseen: 0.299\n",
      "[ Epoch: 8  TLoss: 8.264    Best_HMean:  0.323 ACC_seen: 0.344, ACC_unseen: 0.297\n",
      "[ Epoch: 9  TLoss: 8.251    Best_HMean:  0.323 ACC_seen: 0.337, ACC_unseen: 0.299\n",
      "[ Epoch: 10  TLoss: 8.208    Best_HMean:  0.323 ACC_seen: 0.339, ACC_unseen: 0.300\n",
      "[ Epoch: 11  TLoss: 8.229    Best_HMean:  0.323 ACC_seen: 0.337, ACC_unseen: 0.308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch: 12  TLoss: 8.213    Best_HMean:  0.323 ACC_seen: 0.336, ACC_unseen: 0.303\n",
      "[ Epoch: 13  TLoss: 8.225    Best_HMean:  0.325 ACC_seen: 0.336, ACC_unseen: 0.315\n",
      "[ Epoch: 14  TLoss: 8.222    Best_HMean:  0.331 ACC_seen: 0.339, ACC_unseen: 0.324\n",
      "[ Epoch: 15  TLoss: 8.197    Best_HMean:  0.331 ACC_seen: 0.333, ACC_unseen: 0.327\n",
      "[ Epoch: 16  TLoss: 8.206    Best_HMean:  0.336 ACC_seen: 0.333, ACC_unseen: 0.339\n",
      "[ Epoch: 17  TLoss: 8.190    Best_HMean:  0.340 ACC_seen: 0.342, ACC_unseen: 0.339\n",
      "[ Epoch: 18  TLoss: 8.195    Best_HMean:  0.340 ACC_seen: 0.338, ACC_unseen: 0.324\n",
      "[ Epoch: 19  TLoss: 8.221    Best_HMean:  0.340 ACC_seen: 0.337, ACC_unseen: 0.326\n",
      "[ Epoch: 20  TLoss: 8.206    Best_HMean:  0.340 ACC_seen: 0.336, ACC_unseen: 0.321\n",
      "[ Epoch: 21  TLoss: 8.191    Best_HMean:  0.340 ACC_seen: 0.335, ACC_unseen: 0.311\n",
      "[ Epoch: 22  TLoss: 8.222    Best_HMean:  0.340 ACC_seen: 0.328, ACC_unseen: 0.310\n",
      "[ Epoch: 23  TLoss: 8.197    Best_HMean:  0.340 ACC_seen: 0.328, ACC_unseen: 0.311\n",
      "[ Epoch: 24  TLoss: 8.196    Best_HMean:  0.340 ACC_seen: 0.326, ACC_unseen: 0.311\n",
      "[ Epoch: 25  TLoss: 8.172    Best_HMean:  0.340 ACC_seen: 0.327, ACC_unseen: 0.317\n",
      "[ Epoch: 26  TLoss: 8.200    Best_HMean:  0.340 ACC_seen: 0.327, ACC_unseen: 0.324\n",
      "[ Epoch: 27  TLoss: 8.185    Best_HMean:  0.340 ACC_seen: 0.326, ACC_unseen: 0.329\n",
      "[ Epoch: 28  TLoss: 8.184    Best_HMean:  0.340 ACC_seen: 0.326, ACC_unseen: 0.329\n",
      "[ Epoch: 29  TLoss: 8.174    Best_HMean:  0.340 ACC_seen: 0.329, ACC_unseen: 0.329\n",
      "[ Epoch: 30  TLoss: 8.155    Best_HMean:  0.340 ACC_seen: 0.328, ACC_unseen: 0.332\n",
      "[ Epoch: 31  TLoss: 8.156    Best_HMean:  0.340 ACC_seen: 0.326, ACC_unseen: 0.333\n",
      "[ Epoch: 32  TLoss: 8.151    Best_HMean:  0.340 ACC_seen: 0.327, ACC_unseen: 0.332\n",
      "[ Epoch: 33  TLoss: 8.135    Best_HMean:  0.340 ACC_seen: 0.328, ACC_unseen: 0.335\n",
      "[ Epoch: 34  TLoss: 8.150    Best_HMean:  0.340 ACC_seen: 0.330, ACC_unseen: 0.334\n",
      "[ Epoch: 35  TLoss: 8.154    Best_HMean:  0.340 ACC_seen: 0.331, ACC_unseen: 0.334\n",
      "[ Epoch: 36  TLoss: 8.143    Best_HMean:  0.340 ACC_seen: 0.331, ACC_unseen: 0.329\n",
      "[ Epoch: 37  TLoss: 8.137    Best_HMean:  0.340 ACC_seen: 0.330, ACC_unseen: 0.330\n",
      "[ Epoch: 38  TLoss: 8.160    Best_HMean:  0.340 ACC_seen: 0.330, ACC_unseen: 0.326\n",
      "[ Epoch: 39  TLoss: 8.155    Best_HMean:  0.340 ACC_seen: 0.328, ACC_unseen: 0.323\n",
      "[ Epoch: 40  TLoss: 8.169    Best_HMean:  0.340 ACC_seen: 0.327, ACC_unseen: 0.324\n",
      "[ Epoch: 41  TLoss: 8.132    Best_HMean:  0.340 ACC_seen: 0.328, ACC_unseen: 0.324\n",
      "[ Epoch: 42  TLoss: 8.160    Best_HMean:  0.340 ACC_seen: 0.329, ACC_unseen: 0.326\n",
      "[ Epoch: 43  TLoss: 8.151    Best_HMean:  0.340 ACC_seen: 0.330, ACC_unseen: 0.326\n",
      "[ Epoch: 44  TLoss: 8.139    Best_HMean:  0.340 ACC_seen: 0.331, ACC_unseen: 0.329\n",
      "[ Epoch: 45  TLoss: 8.154    Best_HMean:  0.340 ACC_seen: 0.328, ACC_unseen: 0.330\n",
      "[ Epoch: 46  TLoss: 8.149    Best_HMean:  0.340 ACC_seen: 0.330, ACC_unseen: 0.331\n",
      "[ Epoch: 47  TLoss: 8.142    Best_HMean:  0.340 ACC_seen: 0.329, ACC_unseen: 0.329\n",
      "[ Epoch: 48  TLoss: 8.153    Best_HMean:  0.340 ACC_seen: 0.331, ACC_unseen: 0.329\n",
      "[ Epoch: 49  TLoss: 8.142    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.331\n",
      "[ Epoch: 50  TLoss: 8.135    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.331\n",
      "[ Epoch: 51  TLoss: 8.142    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.331\n",
      "[ Epoch: 52  TLoss: 8.149    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.331\n",
      "[ Epoch: 53  TLoss: 8.124    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.331\n",
      "[ Epoch: 54  TLoss: 8.141    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.330\n",
      "[ Epoch: 55  TLoss: 8.132    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.330\n",
      "[ Epoch: 56  TLoss: 8.137    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.330\n",
      "[ Epoch: 57  TLoss: 8.151    Best_HMean:  0.340 ACC_seen: 0.333, ACC_unseen: 0.330\n",
      "[ Epoch: 58  TLoss: 8.127    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.330\n",
      "[ Epoch: 59  TLoss: 8.126    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.330\n",
      "[ Epoch: 60  TLoss: 8.137    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 61  TLoss: 8.146    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 62  TLoss: 8.144    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.330\n",
      "[ Epoch: 63  TLoss: 8.147    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.330\n",
      "[ Epoch: 64  TLoss: 8.143    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 65  TLoss: 8.129    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.330\n",
      "[ Epoch: 66  TLoss: 8.132    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.330\n",
      "[ Epoch: 67  TLoss: 8.139    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.331\n",
      "[ Epoch: 68  TLoss: 8.131    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.331\n",
      "[ Epoch: 69  TLoss: 8.147    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.331\n",
      "[ Epoch: 70  TLoss: 8.135    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.330\n",
      "[ Epoch: 71  TLoss: 8.136    Best_HMean:  0.340 ACC_seen: 0.331, ACC_unseen: 0.329\n",
      "[ Epoch: 72  TLoss: 8.123    Best_HMean:  0.340 ACC_seen: 0.331, ACC_unseen: 0.330\n",
      "[ Epoch: 73  TLoss: 8.137    Best_HMean:  0.340 ACC_seen: 0.331, ACC_unseen: 0.329\n",
      "[ Epoch: 74  TLoss: 8.145    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 75  TLoss: 8.137    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.328\n",
      "[ Epoch: 76  TLoss: 8.116    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.328\n",
      "[ Epoch: 77  TLoss: 8.138    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.328\n",
      "[ Epoch: 78  TLoss: 8.133    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.328\n",
      "[ Epoch: 79  TLoss: 8.158    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.328\n",
      "[ Epoch: 80  TLoss: 8.132    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.328\n",
      "[ Epoch: 81  TLoss: 8.155    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.328\n",
      "[ Epoch: 82  TLoss: 8.115    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 83  TLoss: 8.135    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 84  TLoss: 8.136    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 85  TLoss: 8.125    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 86  TLoss: 8.128    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 87  TLoss: 8.147    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 88  TLoss: 8.123    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 89  TLoss: 8.127    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 90  TLoss: 8.119    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 91  TLoss: 8.143    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 92  TLoss: 8.130    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 93  TLoss: 8.135    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 94  TLoss: 8.143    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 95  TLoss: 8.127    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 96  TLoss: 8.132    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 97  TLoss: 8.147    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 98  TLoss: 8.143    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[ Epoch: 99  TLoss: 8.133    Best_HMean:  0.340 ACC_seen: 0.332, ACC_unseen: 0.329\n",
      "[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233], [0.26659650816827546, 0.1833332416667125, 0.2172605926922656], [0.29156026543504593, 0.2041665645833844, 0.24015991936801118], [0.29192475565473125, 0.22175914837968508, 0.2520498878649059], [0.3149413446758019, 0.23463529934901697, 0.2689210230777258], [0.32659144220220343, 0.2630951065476848, 0.2914246915277531], [0.30462223654886766, 0.27187486406256794, 0.28731845854669674], [0.3347007995023005, 0.28312485843757074, 0.306760055236337], [0.3083210300133327, 0.32265608867195567, 0.3153257214990356], [0.3271929207856598, 0.30833317916674374, 0.31748321107268634], [0.3210710408278093, 0.3208331729167469, 0.3209520627993916], [0.34231807866623465, 0.338541497395918, 0.3404193140900518]]\n",
      "[[[0.362410360814611, 0.07656712589554154, 0.12642434093966576], [0.2793431795735104, 0.11597104955861648, 0.16389858666763735], [0.24825155217549252, 0.15225686831601026, 0.18875010838695233], [0.26659650816827546, 0.1833332416667125, 0.2172605926922656], [0.29156026543504593, 0.2041665645833844, 0.24015991936801118], [0.29192475565473125, 0.22175914837968508, 0.2520498878649059], [0.3149413446758019, 0.23463529934901697, 0.2689210230777258], [0.32659144220220343, 0.2630951065476848, 0.2914246915277531], [0.30462223654886766, 0.27187486406256794, 0.28731845854669674], [0.3347007995023005, 0.28312485843757074, 0.306760055236337], [0.3083210300133327, 0.32265608867195567, 0.3153257214990356], [0.3271929207856598, 0.30833317916674374, 0.31748321107268634], [0.3210710408278093, 0.3208331729167469, 0.3209520627993916], [0.34231807866623465, 0.338541497395918, 0.3404193140900518]]]\n"
     ]
    }
   ],
   "source": [
    "attributes=attributes.to(torch.float32).to(DEVICE)\n",
    "\n",
    "Overall_hmean=[]\n",
    "\n",
    "print('\\n<=============== Training Samples %s===============>')\n",
    "\n",
    "task_best_hmean=[]\n",
    "for task in range(args.task-1):\n",
    "    best_hmean=0\n",
    "    reg=1.0\n",
    "\n",
    "    print('\\n<=============== Training task %s===============>' % task)\n",
    "    # Build model, optimizer, and set states\n",
    "    if task == 0:\n",
    "        net = ZSLModel(args.attri_dim, args.hdim, args.feat_dim).to(DEVICE)\n",
    "        if args.cuda:\n",
    "            net.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0005, weight_decay=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.1, step_size=25)\n",
    "\n",
    "\n",
    "    train_seen,test_seen,test_unseen=task_data(task+1)\n",
    "    imgs,labels=train_seen[0],train_seen[1]\n",
    "\n",
    "    task_seen_class=all_class[:int(np.sum(args.task_split[:task+1]))]\n",
    "    task_unseen_class=all_class[int(np.sum(args.task_split[:task+1])):]\n",
    "\n",
    "    train_dataloader = DataLoader(TensorDataset(imgs,labels), batch_size=256, shuffle=True) # 256\n",
    "    testseen_dataloader = DataLoader(TensorDataset(test_seen[0],test_seen[1]), batch_size=2048)\n",
    "    testunseen_dataloader = DataLoader(TensorDataset(test_unseen[0],test_unseen[1]), batch_size=2048)\n",
    "\n",
    "    for epoch in range(args.iterations):          \n",
    "\n",
    "        loss = do_learning(net, optimizer, task+1, epoch)\n",
    "        ACC_seen, ACC_unseen,H_mean=test(task+1,task_seen_class,task_unseen_class,reg)\n",
    "\n",
    "        if H_mean>best_hmean:\n",
    "            best_hmean=H_mean\n",
    "            result=[ACC_seen, ACC_unseen,H_mean]\n",
    "        if epoch%1==0:\n",
    "            print('[ Epoch: %d  TLoss: %0.3f    Best_HMean:  %0.3f ACC_seen: %0.3f, ACC_unseen: %0.3f'\n",
    "                  %(epoch,loss,best_hmean,ACC_seen,ACC_unseen))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    task_best_hmean.append(result)\n",
    "\n",
    "    print(task_best_hmean)\n",
    "Overall_hmean.append(task_best_hmean)\n",
    "print(Overall_hmean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3689509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30856039 0.23551058 0.25979628]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(Overall_hmean[0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f22dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8fb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d18a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13d15b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d025c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e13fdd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f818a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
